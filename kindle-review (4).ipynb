{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":9476030,"sourceType":"datasetVersion","datasetId":5763237}],"dockerImageVersionId":30776,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"README FILE\n\n```markdown\n# Sentiment Analysis of Kindle Reviews\n\nThis project implements a sentiment analysis model for Kindle reviews using the Fastai library and a text classification approach based on the AWD-LSTM model. The model classifies reviews into three sentiment categories: negative, neutral, and positive.\n\n## Table of Contents\n- [Introduction](#introduction)\n- [Installation](#installation)\n- [Dataset](#dataset)\n- [Usage](#usage)\n- [Model Training](#model-training)\n- [Results](#results)\n- [Acknowledgments](#acknowledgments)\n\n## Introduction\n\nThis project focuses on analyzing customer sentiments from Kindle reviews. By employing machine learning techniques, the goal is to categorize reviews into different sentiment classes, providing insights into user experiences with Kindle products.\n\n## Installation\n\nTo run this project, ensure you have the following libraries installed:\n\n```bash\npip install fastai\npip install pandas\npip install scikit-learn\n```\n\n## Dataset\n\nThe dataset used for this project is a collection of Kindle reviews, which includes columns for the review text and corresponding ratings. The ratings have been transformed into sentiment categories as follows:\n- Ratings 1 and 2: Negative\n- Rating 3: Neutral\n- Ratings 4 and 5: Positive\n\n## Usage\n\nLoad the dataset:\n\n```python\nimport pandas as pd\n\ndf = pd.read_csv('path/to/kindle_reviews.csv')\n```\n\nPreprocess the data by cleaning text and classifying sentiments. Create DataLoaders for training and validation:\n\n```python\nfrom fastai.text.all import *\n\ndls = TextDataLoaders.from_df(\n    df,\n    text_col='reviewText',\n    label_col='sentiment',\n    valid_pct=0.2,\n    bs=16\n)\n```\n\nInitialize the learner and train the model:\n\n```python\nlearn = text_classifier_learner(dls, AWD_LSTM, drop_mult=0.5, metrics=accuracy)\nlearn.fit_one_cycle(10)\n```\n\n## Model Training\n\nThe model is trained using a one-cycle learning rate policy for optimal performance. The training process includes freezing and unfreezing layers to fine-tune the learning:\n\n```python\nlearn.freeze_to(-2)\nlearn.fit_one_cycle(1, slice(1e-2/(2.6**4), 1e-2))\nlearn.unfreeze()\nlearn.fit_one_cycle(2, slice(1e-3/(2.6**4), 1e-3))\n```\n\n## Results\n\nThe model's performance can be evaluated using metrics such as precision, recall, and F1-score. Example classification results are as follows:\n\n```\n              precision    recall  f1-score   support\n\n    negative       0.90      0.78      0.84        36\n     neutral       0.00      0.00      0.00         8\n    positive       0.74      0.86      0.79        36\n\n    accuracy                           0.74        80\n   macro avg       0.55      0.55      0.54        80\nweighted avg       0.74      0.74      0.73        80\n```\n\n## Acknowledgments\n\n- Fastai documentation for providing excellent resources for model training.\n- Contributors and maintainers of the libraries used in this project.","metadata":{}},{"cell_type":"markdown","source":"Import Fastext as Fastai to replicate the  code  for  ULimFit on new dataset","metadata":{}},{"cell_type":"code","source":"!pip install fastai","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-10-31T11:09:49.170085Z","iopub.execute_input":"2024-10-31T11:09:49.170624Z","iopub.status.idle":"2024-10-31T11:10:01.090491Z","shell.execute_reply.started":"2024-10-31T11:09:49.170558Z","shell.execute_reply":"2024-10-31T11:10:01.089243Z"},"trusted":true},"execution_count":50,"outputs":[{"name":"stdout","text":"Requirement already satisfied: fastai in /opt/conda/lib/python3.10/site-packages (2.7.17)\nRequirement already satisfied: pip in /opt/conda/lib/python3.10/site-packages (from fastai) (24.0)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from fastai) (21.3)\nRequirement already satisfied: fastdownload<2,>=0.0.5 in /opt/conda/lib/python3.10/site-packages (from fastai) (0.0.7)\nRequirement already satisfied: fastcore<1.8,>=1.5.29 in /opt/conda/lib/python3.10/site-packages (from fastai) (1.7.8)\nRequirement already satisfied: torchvision>=0.11 in /opt/conda/lib/python3.10/site-packages (from fastai) (0.19.0)\nRequirement already satisfied: matplotlib in /opt/conda/lib/python3.10/site-packages (from fastai) (3.7.5)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from fastai) (2.2.2)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from fastai) (2.32.3)\nRequirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from fastai) (6.0.2)\nRequirement already satisfied: fastprogress>=0.2.4 in /opt/conda/lib/python3.10/site-packages (from fastai) (1.0.3)\nRequirement already satisfied: pillow>=9.0.0 in /opt/conda/lib/python3.10/site-packages (from fastai) (10.3.0)\nRequirement already satisfied: scikit-learn in /opt/conda/lib/python3.10/site-packages (from fastai) (1.2.2)\nRequirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from fastai) (1.14.1)\nRequirement already satisfied: spacy<4 in /opt/conda/lib/python3.10/site-packages (from fastai) (3.7.5)\nRequirement already satisfied: torch<2.5,>=1.10 in /opt/conda/lib/python3.10/site-packages (from fastai) (2.4.0)\nRequirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /opt/conda/lib/python3.10/site-packages (from spacy<4->fastai) (3.0.12)\nRequirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from spacy<4->fastai) (1.0.5)\nRequirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /opt/conda/lib/python3.10/site-packages (from spacy<4->fastai) (1.0.10)\nRequirement already satisfied: cymem<2.1.0,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from spacy<4->fastai) (2.0.8)\nRequirement already satisfied: preshed<3.1.0,>=3.0.2 in /opt/conda/lib/python3.10/site-packages (from spacy<4->fastai) (3.0.9)\nRequirement already satisfied: thinc<8.3.0,>=8.2.2 in /opt/conda/lib/python3.10/site-packages (from spacy<4->fastai) (8.2.5)\nRequirement already satisfied: wasabi<1.2.0,>=0.9.1 in /opt/conda/lib/python3.10/site-packages (from spacy<4->fastai) (1.1.2)\nRequirement already satisfied: srsly<3.0.0,>=2.4.3 in /opt/conda/lib/python3.10/site-packages (from spacy<4->fastai) (2.4.8)\nRequirement already satisfied: catalogue<2.1.0,>=2.0.6 in /opt/conda/lib/python3.10/site-packages (from spacy<4->fastai) (2.0.10)\nRequirement already satisfied: weasel<0.5.0,>=0.1.0 in /opt/conda/lib/python3.10/site-packages (from spacy<4->fastai) (0.4.1)\nRequirement already satisfied: typer<1.0.0,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from spacy<4->fastai) (0.12.3)\nRequirement already satisfied: tqdm<5.0.0,>=4.38.0 in /opt/conda/lib/python3.10/site-packages (from spacy<4->fastai) (4.66.4)\nRequirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /opt/conda/lib/python3.10/site-packages (from spacy<4->fastai) (2.9.2)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from spacy<4->fastai) (3.1.4)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from spacy<4->fastai) (70.0.0)\nRequirement already satisfied: langcodes<4.0.0,>=3.2.0 in /opt/conda/lib/python3.10/site-packages (from spacy<4->fastai) (3.4.0)\nRequirement already satisfied: numpy>=1.19.0 in /opt/conda/lib/python3.10/site-packages (from spacy<4->fastai) (1.26.4)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->fastai) (3.1.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->fastai) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->fastai) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->fastai) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->fastai) (2024.8.30)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch<2.5,>=1.10->fastai) (3.15.1)\nRequirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.10/site-packages (from torch<2.5,>=1.10->fastai) (4.12.2)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch<2.5,>=1.10->fastai) (1.13.3)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch<2.5,>=1.10->fastai) (3.3)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch<2.5,>=1.10->fastai) (2024.6.1)\nRequirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->fastai) (1.2.1)\nRequirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib->fastai) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->fastai) (4.53.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->fastai) (1.4.5)\nRequirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.10/site-packages (from matplotlib->fastai) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->fastai) (2024.1)\nRequirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas->fastai) (2024.1)\nRequirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->fastai) (1.4.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->fastai) (3.5.0)\nRequirement already satisfied: language-data>=1.2 in /opt/conda/lib/python3.10/site-packages (from langcodes<4.0.0,>=3.2.0->spacy<4->fastai) (1.2.0)\nRequirement already satisfied: annotated-types>=0.6.0 in /opt/conda/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<4->fastai) (0.7.0)\nRequirement already satisfied: pydantic-core==2.23.4 in /opt/conda/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<4->fastai) (2.23.4)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib->fastai) (1.16.0)\nRequirement already satisfied: blis<0.8.0,>=0.7.8 in /opt/conda/lib/python3.10/site-packages (from thinc<8.3.0,>=8.2.2->spacy<4->fastai) (0.7.10)\nRequirement already satisfied: confection<1.0.0,>=0.0.1 in /opt/conda/lib/python3.10/site-packages (from thinc<8.3.0,>=8.2.2->spacy<4->fastai) (0.1.4)\nRequirement already satisfied: click>=8.0.0 in /opt/conda/lib/python3.10/site-packages (from typer<1.0.0,>=0.3.0->spacy<4->fastai) (8.1.7)\nRequirement already satisfied: shellingham>=1.3.0 in /opt/conda/lib/python3.10/site-packages (from typer<1.0.0,>=0.3.0->spacy<4->fastai) (1.5.4)\nRequirement already satisfied: rich>=10.11.0 in /opt/conda/lib/python3.10/site-packages (from typer<1.0.0,>=0.3.0->spacy<4->fastai) (13.7.1)\nRequirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from weasel<0.5.0,>=0.1.0->spacy<4->fastai) (0.19.0)\nRequirement already satisfied: smart-open<8.0.0,>=5.2.1 in /opt/conda/lib/python3.10/site-packages (from weasel<0.5.0,>=0.1.0->spacy<4->fastai) (7.0.4)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->spacy<4->fastai) (2.1.5)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch<2.5,>=1.10->fastai) (1.3.0)\nRequirement already satisfied: marisa-trie>=0.7.7 in /opt/conda/lib/python3.10/site-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy<4->fastai) (1.1.0)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/lib/python3.10/site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<4->fastai) (3.0.0)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<4->fastai) (2.18.0)\nRequirement already satisfied: wrapt in /opt/conda/lib/python3.10/site-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy<4->fastai) (1.16.0)\nRequirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<4->fastai) (0.1.2)\n","output_type":"stream"}]},{"cell_type":"markdown","source":"This code imports all modules and functions from the fastai.text.all library for natural language processing tasks, and it imports the pandas library as pd for data manipulation and analysis.","metadata":{}},{"cell_type":"code","source":"from fastai.text.all import *\nimport pandas as pd","metadata":{"execution":{"iopub.status.busy":"2024-10-31T11:10:01.093209Z","iopub.execute_input":"2024-10-31T11:10:01.093659Z","iopub.status.idle":"2024-10-31T11:10:01.100938Z","shell.execute_reply.started":"2024-10-31T11:10:01.093608Z","shell.execute_reply":"2024-10-31T11:10:01.099934Z"},"trusted":true},"execution_count":51,"outputs":[]},{"cell_type":"markdown","source":"This code imports the os module and then prints a list of all files and directories in the /kaggle/input directory, typically used to display the contents of an input dataset folder in a Kaggle environment.","metadata":{}},{"cell_type":"code","source":"import os\nprint(os.listdir(\"/kaggle/input\"))","metadata":{"execution":{"iopub.status.busy":"2024-10-31T11:10:01.102233Z","iopub.execute_input":"2024-10-31T11:10:01.102601Z","iopub.status.idle":"2024-10-31T11:10:01.113738Z","shell.execute_reply.started":"2024-10-31T11:10:01.102548Z","shell.execute_reply":"2024-10-31T11:10:01.112796Z"},"trusted":true},"execution_count":52,"outputs":[{"name":"stdout","text":"['amazon-kindle-review']\n","output_type":"stream"}]},{"cell_type":"markdown","source":"This code will list all files and directories in the /kaggle/input/amazon-kindle-review directory, showing the contents of the Amazon Kindle Review dataset folder","metadata":{}},{"cell_type":"code","source":"import os\nprint(os.listdir(\"/kaggle/input/amazon-kindle-review\"))","metadata":{"execution":{"iopub.status.busy":"2024-10-31T11:10:01.116390Z","iopub.execute_input":"2024-10-31T11:10:01.116691Z","iopub.status.idle":"2024-10-31T11:10:01.128963Z","shell.execute_reply.started":"2024-10-31T11:10:01.116660Z","shell.execute_reply":"2024-10-31T11:10:01.128056Z"},"trusted":true},"execution_count":53,"outputs":[{"name":"stdout","text":"['preprocessed_kindle_review .csv']\n","output_type":"stream"}]},{"cell_type":"markdown","source":"This part restricts the dataset to only 1000rows","metadata":{}},{"cell_type":"code","source":"import pandas as pd\n\n# Load the preprocessed dataset into a DataFrame\ndf = pd.read_csv(\"/kaggle/input/amazon-kindle-review/preprocessed_kindle_review .csv\")  # Adjust the filename if needed\n\n# Restrict to the first 1000 records\ndf_restricted = df.head(1000)\n\n# Display the first few rows of the restricted DataFrame\nprint(df_restricted.head())","metadata":{"execution":{"iopub.status.busy":"2024-10-31T11:10:01.130269Z","iopub.execute_input":"2024-10-31T11:10:01.130633Z","iopub.status.idle":"2024-10-31T11:10:01.214467Z","shell.execute_reply.started":"2024-10-31T11:10:01.130590Z","shell.execute_reply":"2024-10-31T11:10:01.213496Z"},"trusted":true},"execution_count":54,"outputs":[{"name":"stdout","text":"   Unnamed: 0  rating  \\\n0           0       5   \n1           1       1   \n2           2       5   \n3           3       5   \n4           4       5   \n\n                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                reviewText  \\\n0                                                                                                                                                                                                                                                                                                               This book was the very first bookmobile book I bought when I was in the school book club. I loved the story then and I bet a dollar to a donut I will love it again. If my memory serves, I bought this book in 5th grade. That would have been about 1961. I am looking forward to reliving the memories.   \n1  When I read the description for this book, I couldn't wait to read it. Once I downloaded it to my Kindle, I found it extremely hard to keep reading it.  To be honest, I stopped reading halfway through the book. It began slow and remained a slow, uninteresting read.  It lacked passion; not making love passion, but passion for life. Neither Jada or Aaron were interesting characters and the story was too, too `everything is perfect'.  Everybody is just so understanding and accommodating--the bit of drama with his father and her grandmother was blah.  To give an example of what I mean (and the...   \n2  I just had to edit this review. This book is an (I believe I got this right) an updated re-write. Thank god I didn't get the first version. It has moved into MY top 5 favorite. He (BECHETT DeSAXBY) is also in my top 5 Hero/daydream inducing gents.Didn't expect to like it. Seemed a little too debauched. ha ha ha. I freggin loved it. Matter of fact I'm over 21...well over 21...ran my batteries dead..NOW you know what batteries..I am broadening my reading tastes and buying anything Scottie Barrett writes. AN ABSOLUTE KEEPER (with a large supply of batteries).And for once the cover of that hun...   \n3                                                                                                                                                                                                                                          I don't normally buy 'mystery' novels because I just don't like them.  However, this time I decided to take a chance and I am glad I did.I found the story engrossing, the characters engaging, and it was well written.  I will buy more books from this author in this series.I still do not especially care for 'mystery' novels - I consider this book series an exception.   \n4                                                                                                                                                                                                                    This isn't the kind of book I normally read, although I try not to limit myself to certain genres. Sometimes I find epic fantasies a little tedious. Not so with this one! There wasn't one paragraph in this story that didn't hold my interest. Ty Johnston has a wonderful way with words so that his scenes come alive for the reader. I'm definitely buying books two and three of this trilogy!   \n\n                           summary  \n0                50 + years ago...  \n1          Boring! Boring! Boring!  \n2  Wiggleliscious/new toy ready/!!  \n3                  Very good read.  \n4                     Great Story!  \n","output_type":"stream"}]},{"cell_type":"markdown","source":"This code imports the train_test_split function from sklearn.model_selection and then splits the DataFrame df_restricted into training and testing sets. It uses an 80-20 split, where 80% of the data is allocated to train_df and 20% to test_df. The random_state=42 ensures that the split is reproducible. Here, rating is assumed to be the label column, and reviewText is the text column containing the reviews.","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\n# Split the restricted dataset (assuming 'rating' is the label and 'reviewText' is the text column)\ntrain_df, test_df = train_test_split(df_restricted, test_size=0.2, random_state=42)  # 80% train, 20% test","metadata":{"execution":{"iopub.status.busy":"2024-10-31T11:10:01.215589Z","iopub.execute_input":"2024-10-31T11:10:01.215870Z","iopub.status.idle":"2024-10-31T11:10:01.223355Z","shell.execute_reply.started":"2024-10-31T11:10:01.215838Z","shell.execute_reply":"2024-10-31T11:10:01.222451Z"},"trusted":true},"execution_count":55,"outputs":[]},{"cell_type":"markdown","source":"This code defines and applies a function to classify review ratings into sentiment labels, adds the labels to training and test datasets, and saves the results:\n\nclassify_sentiment Function: This function classifies a review rating as:\n\n'negative' if the rating is 1 or 2,\n'neutral' if the rating is 3,\n'positive' if the rating is 4 or 5.\nApplying the Function: The classify_sentiment function is applied to the 'rating' column in both train_df and test_df to create a new 'sentiment' column with the corresponding sentiment label.\n\nDisplay: Prints the first five rows of the train_df and test_df DataFrames, showing the original rating and the new sentiment columns.\n\nSave to CSV: Exports the modified train_df and test_df DataFrames to CSV files named 'train_kindle_reviews_classified.csv' and 'test_kindle_reviews_classified.csv'.","metadata":{}},{"cell_type":"code","source":"# Step 4: Define a function to classify ratings into sentiment\ndef classify_sentiment(rating):\n    if rating in [1, 2]:\n        return 'negative'\n    elif rating == 3:\n        return 'neutral'\n    elif rating in [4, 5]:\n        return 'positive'\n\n# Step 5: Apply the classification function to the 'rating' column\ntrain_df['sentiment'] = train_df['rating'].apply(classify_sentiment)\ntest_df['sentiment'] = test_df['rating'].apply(classify_sentiment)\n\n# Optional: Display the modified DataFrames (first 5 records)\nprint(\"Training Set Sentiment Classification:\")\nprint(train_df[['rating', 'sentiment']].head())\n\nprint(\"\\nTest Set Sentiment Classification:\")\nprint(test_df[['rating', 'sentiment']].head())\n\n# Step 6: Save the modified datasets to new CSV files\ntrain_df.to_csv('train_kindle_reviews_classified.csv', index=False)\ntest_df.to_csv('test_kindle_reviews_classified.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2024-10-31T11:10:01.224594Z","iopub.execute_input":"2024-10-31T11:10:01.224968Z","iopub.status.idle":"2024-10-31T11:10:01.271044Z","shell.execute_reply.started":"2024-10-31T11:10:01.224935Z","shell.execute_reply":"2024-10-31T11:10:01.270104Z"},"trusted":true},"execution_count":56,"outputs":[{"name":"stdout","text":"Training Set Sentiment Classification:\n     rating sentiment\n29        5  positive\n535       4  positive\n695       1  negative\n557       1  negative\n836       2  negative\n\nTest Set Sentiment Classification:\n     rating sentiment\n521       5  positive\n737       5  positive\n740       1  negative\n660       4  positive\n411       4  positive\n","output_type":"stream"}]},{"cell_type":"markdown","source":"This line of code creates a TextDataLoaders object, dls, for training a natural language processing model using the fastai library. It does the following:\n\nfrom_df method: Creates a TextDataLoaders object directly from a DataFrame, train_df.\nParameters:\ntext_col='reviewText': Specifies that the reviewText column contains the text data (the review text).\nlabel_col='sentiment': Specifies that the sentiment column contains the labels (sentiment classification).\nvalid_pct=0.2: Reserves 20% of the data as the validation set, while the remaining 80% is used for training.\nThe resulting dls object can now be used for model training and validation.","metadata":{}},{"cell_type":"code","source":"dls = TextDataLoaders.from_df(train_df, text_col='reviewText', label_col='sentiment', valid_pct=0.2)","metadata":{"execution":{"iopub.status.busy":"2024-10-31T11:10:01.272112Z","iopub.execute_input":"2024-10-31T11:10:01.272531Z","iopub.status.idle":"2024-10-31T11:10:03.261394Z","shell.execute_reply.started":"2024-10-31T11:10:01.272481Z","shell.execute_reply":"2024-10-31T11:10:03.260150Z"},"trusted":true},"execution_count":57,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n<style>\n    /* Turns off some styling */\n    progress {\n        /* gets rid of default border in Firefox and Opera. */\n        border: none;\n        /* Needs to be in here for Safari polyfill so background images work as expected. */\n        background-size: auto;\n    }\n    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n    }\n    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n        background: #F44336;\n    }\n</style>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}}]},{"cell_type":"markdown","source":"The dls.show_batch() command displays a sample batch of text data from the dls data loader. This includes a preview of the reviewText entries (input text) and their corresponding sentiment labels (target labels). This helps verify that the data is correctly prepared for training by showing the format and structure of the data batches that will be fed into the model","metadata":{}},{"cell_type":"code","source":"dls.show_batch()","metadata":{"execution":{"iopub.status.busy":"2024-10-31T11:10:03.262892Z","iopub.execute_input":"2024-10-31T11:10:03.263291Z","iopub.status.idle":"2024-10-31T11:10:03.542166Z","shell.execute_reply.started":"2024-10-31T11:10:03.263235Z","shell.execute_reply":"2024-10-31T11:10:03.541169Z"},"trusted":true},"execution_count":58,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>category</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>xxbos xxmaj i 've read several of xxmaj xxunk 's books over several series . xxmaj before reading this volume , i had read every other volume of this series ( except the xxunk 1 , vol . 7 ; it had not been published when i finished reading the other 5 ) . i had not read this one , because i did n't think the books needed to be read in sequence and the summary for this one just did n't interest me enough to want to read it . xxmaj since i thought 7 xxunk more than what i wanted to pay , and xxmaj i 'd been waiting for several months , a year at least i think , for her to finish the series , because vol . 6 actually ended with a cliff xxunk - i decided to just go ahead and read this</td>\n      <td>negative</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>xxbos xxunk xxunk xxup bell xxup blues can be read on it 's own , but i would not recommend it - as the personalities that i know and love takes a back seat to the drama of the wedding in this second book , but they creep in every now and again and without reading the first book , you will definately be missing xxunk book starts off with small town xxmaj konigsburg xxunk for the wedding of the year , now that xxmaj docia has agreed to marry xxmaj cal . xxmaj as with all not normal wedding with a xxunk mother of the bride - everything went xxunk and larger than life and it is only with the xxunk of xxmaj docia best xxunk xxunk xxmaj janie xxmaj xxunk is she able to survive the day to day angst of her xxunk is sweet , really sweet</td>\n      <td>positive</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>xxbos xxmaj dylan xxmaj xxunk is a xxunk werewolf who spent years under a xxunk alpha who enjoyed nothing more than hurting others . xxmaj it is n't until his friends and new home is xxunk by xxmaj xxunk xxmaj xxunk does he finally take a stand and kill his former pack leader . xxmaj even now in is new home of xxmaj red xxmaj rock and under a much more kind alpha , xxmaj dylan is still xxunk by is inner scars from his previous life . xxmaj he does not just want to sit around and be taken care of by others but wants to help and be of xxunk xxmaj xxunk xxunk as her xxunk was xxunk murdered and left with a few scars of her own but it 's the ones that she ca n't see that hurt her more . xxmaj the xxunk of xxmaj</td>\n      <td>positive</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>xxbos xxmaj beautiful xxmaj demons is the second book by xxmaj xxunk xxmaj xxunk i have read . i did n't love the first one , xxmaj the xxmaj trouble xxmaj with xxmaj xxunk , but i realized i already had this book , and in some reviews for xxup xxunk the reviewers stated they liked this series much better , so i thought i would give it a try . xxmaj while i did like it better than the first book , it still was n't amazing . i will , however , read the second book once i get through some of my library xxunk xxmaj demons starts off with xxmaj harper being sent to another xxunk home . xxmaj this is her last chance . xxmaj she knows there is something different about her , but she tries to keep that secret for good reason . xxmaj</td>\n      <td>negative</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>xxbos xxmaj maybe xxmaj i 'm not as xxunk as the other reviewers , but i really did n't xxunk this hero . xxmaj maybe xxmaj i 'm xxunk and too romantic , but i really wish i had known that not 6 hours after taking h 's virginity , the hero would be xxunk his ex ( maybe not so ex ) xxunk i first started the book , i was enjoying the xxmaj xxunk xxmaj jones feel of the xxunk , awkward heroine , but the hero was no xxmaj mr . xxmaj xxunk . xxmaj when h first meets xxup h , he 's wearing a xxunk that xxunk xxmaj xxunk xxmaj no xxmaj xxunk . xxmaj what guy wears that ? i had to check to make sure this guy was really the xxup h. xxmaj he 's cold and even mean to her in the</td>\n      <td>negative</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>xxbos i really do enjoy xxmaj troy xxmaj denning 's work , i want everyone who reads this review to know this . i loved xxmaj star by xxmaj star and i very much enjoyed xxmaj xxunk xxmaj ghost . xxmaj this book \" a xxmaj forest xxmaj apart \" was n't on par with his other works . xxmaj it was n't without it 's xxunk , but it had things in it that i did n't xxunk story itself is pretty simple . xxmaj it 's a coming of age story for xxmaj chewbacca 's son , and instead of coming of age on xxmaj xxunk xxrep 3 y xxunk , he is growing up on xxmaj coruscant . xxmaj it 's not horrible , and we find out that xxmaj lumpy is an avid xxunk and enjoys playing video games and that he xxunk his father .</td>\n      <td>neutral</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>xxbos xxmaj the xxmaj grimm brothers have nothing on xxmaj xxunk xxmaj walker , who tells a mean tale . xxmaj xxunk . xxmaj this xxunk twist on xxmaj grimm is original , unique , and interesting , and xxmaj walker has xxunk another dark , rich novella to start an exciting new series . xxmaj so much urban fantasy and paranormal romance is based around the idea that there 's always a xxunk of truth in all folk lore and fairy tales , and xxmaj walker not only xxunk that xxunk , she xxunk into it , xxunk it to the ground , and xxunk ties it until it does her xxunk xxmaj candy xxmaj houses , xxmaj greta and xxmaj rip are known to children everywhere as xxmaj xxunk of xxmaj xxunk and xxmaj xxunk xxunk , and xxmaj rip as in xxmaj xxunk xxmaj xxunk , but</td>\n      <td>positive</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>xxbos xxup may xxup xxunk xxup spoilers xxrep 3 * i do n't even know where to start , i had so many issues with this xxunk . xxmaj feels like it was expanded from a novella length . xxmaj there 's an over xxunk of xxunk , both in content and words ( xxunk , no , xxunk / xxunk , xxunk , no , xxunk xxunk , beast / monster , no , xxunk , no , no … ) xxunk . xxmaj world building is lacking , the mc 's are supposedly not human ( and the last of their species ) but very little information is given … and what little we learn is not a plus ( xxunk xxunk xxunk and child xxunk . xxmaj back to the child sex elements . xxmaj call it fantasy / dreams / alien xxunk , it 's still</td>\n      <td>negative</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>xxbos xxmaj this is a short story first published in xxunk as a two part serial in the pulp fiction xxunk xxmaj xxunk . xxmaj the author later decided to develop the characters in three novellas which have also been xxunk to the xxmaj kindle . xxmaj this is a very quick read , and thus since it is so xxunk i recommend that anyone who is interested in the genre and plans to read the xxunk published books ( which i rate highly ) should read it xxunk main character in this book is the detective xxmaj doan , and unfortunately his huge xxmaj great xxmaj dane xxmaj carstairs makes only a xxunk xxunk appearance . xxmaj fortunately , in the xxunk stories xxmaj carstairs plays an xxunk role and adds xxunk to the reader 's enjoyment . xxmaj doan 's xxunk appearance leads his xxunk to xxunk his</td>\n      <td>neutral</td>\n    </tr>\n  </tbody>\n</table>"},"metadata":{}}]},{"cell_type":"markdown","source":"\nThis code initializes a text classification model using the fastai library:\n\ntext_classifier_learner: This function creates a learner object, learn, for training a text classifier.\n\nParameters:\n\ndls: The TextDataLoaders object, which supplies the text data and labels.\nAWD_LSTM: Specifies the architecture, in this case, the AWD_LSTM model, which is an LSTM-based architecture optimized for text classification.\ndrop_mult=0.5: Sets the dropout multiplier to 0.5, which helps prevent overfitting by randomly \"dropping out\" parts of the model during training.\nmetrics=accuracy: Specifies accuracy as the metric to evaluate the model's performance.\nThis learn object is now ready for training with the fit or fine_tune method","metadata":{}},{"cell_type":"code","source":"learn = text_classifier_learner(dls, AWD_LSTM, drop_mult=0.5, metrics=accuracy)","metadata":{"execution":{"iopub.status.busy":"2024-10-31T11:10:03.546085Z","iopub.execute_input":"2024-10-31T11:10:03.546643Z","iopub.status.idle":"2024-10-31T11:10:03.979530Z","shell.execute_reply.started":"2024-10-31T11:10:03.546601Z","shell.execute_reply":"2024-10-31T11:10:03.978502Z"},"trusted":true},"execution_count":59,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/fastai/text/learner.py:149: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  wgts = torch.load(wgts_fname, map_location = lambda storage,loc: storage)\n","output_type":"stream"}]},{"cell_type":"markdown","source":"This code trains the text classifier by fine-tuning the model for 8 epochs:\n\nfine_tune: This method fine-tunes the model, typically starting from a pretrained language model.\n\nParameters:\n\n8: Specifies the number of epochs, or complete passes through the training data.\n1e-2: Sets the learning rate to 0.01, which controls the step size in updating model weights.\nThe model will iteratively improve its accuracy by adjusting weights based on the training data.","metadata":{}},{"cell_type":"code","source":"learn.fine_tune(8, 1e-2)","metadata":{"execution":{"iopub.status.busy":"2024-10-31T11:10:03.981768Z","iopub.execute_input":"2024-10-31T11:10:03.982483Z","iopub.status.idle":"2024-10-31T11:10:53.016542Z","shell.execute_reply.started":"2024-10-31T11:10:03.982435Z","shell.execute_reply":"2024-10-31T11:10:53.015443Z"},"trusted":true},"execution_count":60,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n<style>\n    /* Turns off some styling */\n    progress {\n        /* gets rid of default border in Firefox and Opera. */\n        border: none;\n        /* Needs to be in here for Safari polyfill so background images work as expected. */\n        background-size: auto;\n    }\n    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n    }\n    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n        background: #F44336;\n    }\n</style>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: left;\">\n      <th>epoch</th>\n      <th>train_loss</th>\n      <th>valid_loss</th>\n      <th>accuracy</th>\n      <th>time</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>0</td>\n      <td>1.081885</td>\n      <td>0.967615</td>\n      <td>0.693750</td>\n      <td>00:02</td>\n    </tr>\n  </tbody>\n</table>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n<style>\n    /* Turns off some styling */\n    progress {\n        /* gets rid of default border in Firefox and Opera. */\n        border: none;\n        /* Needs to be in here for Safari polyfill so background images work as expected. */\n        background-size: auto;\n    }\n    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n    }\n    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n        background: #F44336;\n    }\n</style>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: left;\">\n      <th>epoch</th>\n      <th>train_loss</th>\n      <th>valid_loss</th>\n      <th>accuracy</th>\n      <th>time</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>0</td>\n      <td>0.786931</td>\n      <td>0.872388</td>\n      <td>0.681250</td>\n      <td>00:05</td>\n    </tr>\n    <tr>\n      <td>1</td>\n      <td>0.717453</td>\n      <td>0.791598</td>\n      <td>0.687500</td>\n      <td>00:05</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.634586</td>\n      <td>0.739528</td>\n      <td>0.687500</td>\n      <td>00:05</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.560404</td>\n      <td>0.817270</td>\n      <td>0.681250</td>\n      <td>00:05</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>0.473373</td>\n      <td>0.815675</td>\n      <td>0.650000</td>\n      <td>00:05</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>0.397595</td>\n      <td>0.977206</td>\n      <td>0.600000</td>\n      <td>00:05</td>\n    </tr>\n    <tr>\n      <td>6</td>\n      <td>0.336766</td>\n      <td>0.922405</td>\n      <td>0.650000</td>\n      <td>00:05</td>\n    </tr>\n    <tr>\n      <td>7</td>\n      <td>0.288657</td>\n      <td>0.921546</td>\n      <td>0.675000</td>\n      <td>00:05</td>\n    </tr>\n  </tbody>\n</table>"},"metadata":{}}]},{"cell_type":"markdown","source":"The learn.show_results() command displays the model's predictions alongside the actual labels for a batch of data from the validation set. This output includes:\n\nInput text: The review text (from reviewText) used as input to the model.\nPredicted labels: The sentiment classifications predicted by the model.\nActual labels: The true sentiment labels from the dataset.\nThis comparison helps assess how well the model is performing by giving a clear view of its successes and errors in prediction.","metadata":{}},{"cell_type":"code","source":"learn.show_results()","metadata":{"execution":{"iopub.status.busy":"2024-10-31T11:10:53.018380Z","iopub.execute_input":"2024-10-31T11:10:53.018810Z","iopub.status.idle":"2024-10-31T11:10:53.868486Z","shell.execute_reply.started":"2024-10-31T11:10:53.018763Z","shell.execute_reply":"2024-10-31T11:10:53.867392Z"},"trusted":true},"execution_count":61,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n<style>\n    /* Turns off some styling */\n    progress {\n        /* gets rid of default border in Firefox and Opera. */\n        border: none;\n        /* Needs to be in here for Safari polyfill so background images work as expected. */\n        background-size: auto;\n    }\n    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n    }\n    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n        background: #F44336;\n    }\n</style>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>category</th>\n      <th>category_</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>xxbos * * possible xxmaj spoilers * * xxmaj if i had to review this book in one word it would be ' ridiculous ' . i had high hopes the first few pages as the initial crime xxunk . i went into it willing to suspend belief about a xxunk using that xxunk as a cover for her real job as a xxup cia agent . xxmaj when i read xxmaj jaclyn 's back story about her parents and her near xxunk i thought , \" h xxrep 3 m … this is intriguing . xxunk too long though it became xxunk that this book was going to xxunk due to xxunk xxunk guys , silly xxunk type xxunk , and a plot whose xxunk you could xxunk a plane xxunk could have been an interesting thriller was anything but . xxmaj the villain of the piece was presented</td>\n      <td>negative</td>\n      <td>negative</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>xxbos xxmaj you xxmaj can xxmaj leave xxmaj your xxmaj xxunk xxmaj on is what the title promised , a naughty little novella on a stripper and his lover . xxmaj the starting point of the story is one i already see in the past , a young and handsome xxmaj college xxup xxunk , xxmaj harlan , who has the xxunk for his even more handsome , a slightly older , xxmaj college professor , xxmaj sawyer . xxmaj the book xxunk the rules of a xxmaj may / xxmaj xxunk romance plus the xxmaj college setting with an xxmaj office xxmaj xxunk theme … the xxunk the thing , this is the xxunk romance by the rule , with the twist of being a gay romance . xxmaj so i would say that it can appeal both to the old fan of the gay romance than to a</td>\n      <td>positive</td>\n      <td>neutral</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>xxbos xxmaj let me start this review off by saying that no one , and i mean xxup no xxup one can write for xxmaj boba xxmaj fett as well as xxmaj karen xxmaj xxunk can . xxmaj when i saw this book on xxmaj amazon i was delighted and i was even more excited when i found out that she wrote it ! xxrep 3 * xxup spoilers xxrep 3 * xxrep 3 * xxup spoilers xxrep 3 * xxrep 3 * xxup spoilers xxrep 3 * i knew from the xxmaj star xxmaj wars xxunk that the xxmaj mandalorians were involved in the xxmaj vong xxmaj war during their xxunk and that they xxunk alongside them against the xxmaj new xxmaj republic . xxmaj but this e - book really helped fill in the gaps that the xxunk and the novels left . i knew they were n't</td>\n      <td>positive</td>\n      <td>negative</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>xxbos xxmaj after reading ' knowing xxmaj xxunk ' which i absolutely loved , i decided to explore more of this author 's work . xxunk did n't xxunk the way the first book did . i had a few problems . xxmaj ren and xxmaj cade come together fairly early in the book which was fine , but then the sex got repetitive and plot took a xxunk for a few chapters . xxmaj ren and xxmaj cade were xxunk strong and insecure / xxunk , sometimes all within a matter of sentences . xxmaj sometimes i could n't figure exactly what they were xxunk over as the conclusion they would draw from each other 's actions did n't seem xxunk . xxmaj the angst just seemed to be xxunk and drawn out for no good reason . xxmaj cade 's xxunk / xxunk to forgive xxmaj ren 's</td>\n      <td>neutral</td>\n      <td>negative</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>xxbos i just had to xxunk this review . xxmaj this book is an ( i believe i got this right ) an xxunk re - write . xxmaj thank god i did n't get the first version . xxmaj it has moved into xxup my top 5 favorite . xxmaj he ( bechett xxunk ) is also in my top 5 xxmaj hero / xxunk xxunk xxunk expect to like it . xxmaj seemed a little too xxunk . xxwrep 3 xxunk . i xxunk loved it . xxmaj matter of fact xxmaj i 'm over 21 … well over 21 … ran my xxunk dead .. now you know what xxunk .. i am xxunk my reading xxunk and buying anything xxmaj xxunk xxmaj barrett writes . xxup an xxup absolute xxup keeper ( with a large supply of xxunk for once the cover of that xxunk xxunk</td>\n      <td>positive</td>\n      <td>negative</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>xxbos xxmaj xxunk xxmaj property by xxmaj leah xxmaj xxunk is the first book in the xxmaj xxunk xxmaj security series . xxmaj it is also xxmaj leah 's first published work and i enjoyed it so much i knew xxmaj i 'd read anything future she published . xxmaj the characters are interesting , the dialog engaging , and the sex scenes are hot . xxmaj what truly xxunk me though was the fact that this book takes place less than a half of a xxunk from my home and she described it xxunk book xxunk around xxmaj mark xxmaj xxunk and xxmaj jodi xxmaj xxunk . xxmaj mark is the owner of xxmaj xxunk xxmaj security xxunk in xxmaj texas and xxmaj jodi one of his xxunk . xxmaj the book xxunk with xxmaj jodi xxunk out a home she is suppose to break into to prove to</td>\n      <td>positive</td>\n      <td>positive</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>xxbos xxmaj book 3 of xxmaj bell 's \" halle xxmaj pumas \" series . xxmaj xxunk xxunk xxmaj dreams . xxmaj followed xxunk xxunk 1 to 3 are available as a xxunk xxunk xxunk : sheri ca n't keep running from her stalker , and when xxmaj xxunk and xxmaj simon xxunk her to join the xxmaj xxunk , she takes her chance to gain some peace . xxmaj but the stalker is still out there , and getting closer , and now xxmaj adrian wants to xxmaj mate her , is she strong enough to keep them both xxunk xxmaj contemporary paranormal ( xxunk shifting ) xxunk romance with explicit bedroom xxunk xxunk kindle locations , 20 , xxrep 3 0 words ( short novella ) , but finishes around xxunk xxunk m / f - explicit , xxunk frequent , * xxunk \" cat of a xxmaj</td>\n      <td>positive</td>\n      <td>positive</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>xxbos xxmaj meet xxmaj cody xxunk , a cowboy with bright blue eyes and owner of xxmaj xxunk xxmaj ranch in xxmaj texas . xxmaj xxunk xxmaj xxunk , an xxunk . comes to xxunk xxmaj cody that his family may be in danger as xxmaj cody 's name has recently come up in a fight with \" some especially cruel and xxunk xxunk . \" xxmaj xxunk is available to help if needed . xxmaj cody is not that surprised by the news as he has been having dreams and visions of xxunk and things . xxmaj the bad xxunk is also not xxunk xxmaj cody feel any better as the ranch is losing money . xxmaj he has to do something and xxunk than he xxunk with all that , xxmaj cody is in a ' red - xxunk ' xxunk enjoying all kinds of xxunk but mostly</td>\n      <td>neutral</td>\n      <td>negative</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>xxbos xxmaj xxunk xxmaj rolanda xxmaj xxunk had been xxunk by a xxunk ! xxmaj she was supposed to be in xxmaj xxunk to xxunk xxunk ; but , instead she was standing before a very handsome stranger who introduced himself as xxmaj shahryar with the xxunk for her to tell him a story each night for the next one thousand and one nights . xxmaj what came as an even more of a xxunk to xxmaj rolanda was that he knew her erotic romance writing pen xxunk her time while xxunk her escape , xxmaj rolanda xxunk her first night 's fiction xxunk xxmaj positively xxmaj despotic … in the land of xxmaj xxunk - where two brothers were xxunk by magic , by birth and the love of one woman - as long as the xxunk was whole , the land would be xxunk and xxunk ; however</td>\n      <td>positive</td>\n      <td>positive</td>\n    </tr>\n  </tbody>\n</table>"},"metadata":{}}]},{"cell_type":"markdown","source":"The learn.predict(\"I really liked that movie!\") command uses the trained text classification model to make a sentiment prediction for the given input text (\"I really liked that movie!\"). The output will typically include:\n\nPredicted label: The sentiment classification (e.g., 'positive', 'negative', or 'neutral').\nPredicted probabilities: The model's confidence scores for each possible class.\nInput text: The original input that was analyzed.\nThis allows you to see how the model interprets the sentiment of the provided text.","metadata":{}},{"cell_type":"code","source":"learn.predict(\"I really liked that movie!\")","metadata":{"execution":{"iopub.status.busy":"2024-10-31T11:10:53.869774Z","iopub.execute_input":"2024-10-31T11:10:53.870105Z","iopub.status.idle":"2024-10-31T11:10:53.909738Z","shell.execute_reply.started":"2024-10-31T11:10:53.870068Z","shell.execute_reply":"2024-10-31T11:10:53.908775Z"},"trusted":true},"execution_count":62,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n<style>\n    /* Turns off some styling */\n    progress {\n        /* gets rid of default border in Firefox and Opera. */\n        border: none;\n        /* Needs to be in here for Safari polyfill so background images work as expected. */\n        background-size: auto;\n    }\n    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n    }\n    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n        background: #F44336;\n    }\n</style>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"execution_count":62,"output_type":"execute_result","data":{"text/plain":"('positive', tensor(2), tensor([4.9671e-04, 1.7732e-04, 9.9933e-01]))"},"metadata":{}}]},{"cell_type":"markdown","source":"The two lines of code serve the following purposes:\n\nprint(train_df.dtypes): This prints the data types of each column in the train_df DataFrame. It helps you understand what types of data you are working with (e.g., integers, floats, strings, etc.).\n\nprint(train_df['reviewText'].apply(type).value_counts()): This line applies the type function to each entry in the 'reviewText' column to determine the type of each review (e.g., str for strings). It then counts how many entries of each type are present in that column and prints the results. This is useful for confirming that all entries in the 'reviewText' column are of the expected type (typically strings for text data).","metadata":{}},{"cell_type":"code","source":"print(train_df.dtypes)\nprint(train_df['reviewText'].apply(type).value_counts())\n","metadata":{"execution":{"iopub.status.busy":"2024-10-31T11:10:53.911243Z","iopub.execute_input":"2024-10-31T11:10:53.911549Z","iopub.status.idle":"2024-10-31T11:10:53.919155Z","shell.execute_reply.started":"2024-10-31T11:10:53.911516Z","shell.execute_reply":"2024-10-31T11:10:53.918178Z"},"trusted":true},"execution_count":63,"outputs":[{"name":"stdout","text":"Unnamed: 0     int64\nrating         int64\nreviewText    object\nsummary       object\nsentiment     object\ndtype: object\nreviewText\n<class 'str'>    800\nName: count, dtype: int64\n","output_type":"stream"}]},{"cell_type":"markdown","source":"The two lines of code perform text preprocessing on the 'reviewText' column of the train_df DataFrame:\n\ntrain_df['reviewText'] = train_df['reviewText'].str.replace('\\n', ' '): This replaces any newline characters (\\n) in the review text with a space. This is helpful for ensuring that the text is formatted correctly and does not contain unwanted line breaks, which could interfere with model training.\n\ntrain_df['reviewText'] = train_df['reviewText'].str.strip(): This removes any leading or trailing whitespace from the review text. This ensures that there are no extra spaces at the beginning or end of the reviews, which could affect text processing and model performance.\n\nThese steps help clean the text data, making it more suitable for analysis and model training.","metadata":{}},{"cell_type":"code","source":"train_df['reviewText'] = train_df['reviewText'].str.replace('\\n', ' ')  # Replace newline characters\ntrain_df['reviewText'] = train_df['reviewText'].str.strip()  # Strip leading/trailing whitespace\n","metadata":{"execution":{"iopub.status.busy":"2024-10-31T11:10:53.920354Z","iopub.execute_input":"2024-10-31T11:10:53.920703Z","iopub.status.idle":"2024-10-31T11:10:53.930970Z","shell.execute_reply.started":"2024-10-31T11:10:53.920667Z","shell.execute_reply":"2024-10-31T11:10:53.930025Z"},"trusted":true},"execution_count":64,"outputs":[]},{"cell_type":"markdown","source":"These lines of code perform a cleanup operation on the 'sentiment' column of the train_df DataFrame:\n\ntrain_df['sentiment'] = train_df['sentiment'].str.strip(): This line removes any leading or trailing whitespace from the sentiment labels. This is important to ensure that there are no extra spaces around the labels, which could lead to issues when analyzing or using the data.\n\nprint(train_df['sentiment'].unique()): This line prints the unique values present in the 'sentiment' column after the cleanup. It allows you to verify the distinct sentiment categories in the dataset (e.g., 'positive', 'neutral', 'negative') and ensures that they are formatted correctly without any unintended whitespace.","metadata":{}},{"cell_type":"code","source":"train_df['sentiment'] = train_df['sentiment'].str.strip()  # Strip spaces\nprint(train_df['sentiment'].unique()) ","metadata":{"execution":{"iopub.status.busy":"2024-10-31T11:10:53.932131Z","iopub.execute_input":"2024-10-31T11:10:53.932474Z","iopub.status.idle":"2024-10-31T11:10:53.941322Z","shell.execute_reply.started":"2024-10-31T11:10:53.932440Z","shell.execute_reply":"2024-10-31T11:10:53.940347Z"},"trusted":true},"execution_count":65,"outputs":[{"name":"stdout","text":"['positive' 'negative' 'neutral']\n","output_type":"stream"}]},{"cell_type":"markdown","source":"The line of code print(train_df[['reviewText', 'sentiment']].head()) displays the first five rows of the specified columns ('reviewText' and 'sentiment') from the train_df DataFrame.\n\nThis allows you to:\n\nVerify Data: Check that the review texts and their corresponding sentiment labels are correctly aligned and formatted after any preprocessing.\nUnderstand Data Structure: Get a quick overview of the data you're working with, including examples of the reviews and their classified sentiments.\nThis step is useful for confirming that the data preparation steps have been successful and that the data is ready for model training or further analysis.","metadata":{}},{"cell_type":"code","source":"print(train_df[['reviewText', 'sentiment']].head())  # Check specific columns\n","metadata":{"execution":{"iopub.status.busy":"2024-10-31T11:10:53.942573Z","iopub.execute_input":"2024-10-31T11:10:53.943039Z","iopub.status.idle":"2024-10-31T11:10:53.953071Z","shell.execute_reply.started":"2024-10-31T11:10:53.942988Z","shell.execute_reply":"2024-10-31T11:10:53.952217Z"},"trusted":true},"execution_count":66,"outputs":[{"name":"stdout","text":"                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  reviewText  \\\n29   I have read tons of books, and this is one of the best books I've ever read! Imagine the concept of a hitch-hiking serial killer being picked up by a serial killer! It's hilarious! I've read all the versions and prequels and sequels that Kilborn and Crouch wrote about these characters, and let me tell you they are all great! They have some really twisted minds, and I love that. Kinda reminds me of myself lol. Keep it up you two, because I want to read more of your stuff! And don't ever hitchhike!!!   \n535                                                                                                                                                                                                                                                                                                                                       A great read. Nate and Emery's story was sweet. I really enjoyed the book from start to finish.  The electricity involved between them was epic. We need a few more men like Nate.   \n695                                                                                                                                                                                                                                                                                                                                               Ok I bought this because it was free and thought a cute short story - half way through it does this weird twist and I started laughing.  Not streamy but stupid - skip it.   \n557                                                                                                                                                                                                                                                                                                                                                                                   Poorly written.  Good story.  Needs editor.  Rambles.  I would avoid the work--but give the author another chance should he try again.   \n836                                                                                                                                                                                                                                                                                      This book is not one of my faviourties, but that may be because I was not expecting the unexpected, I did read the whole book and enjoyed the story line and some of the quirky lines, and the story flowed.sorry it is me not you.   \n\n    sentiment  \n29   positive  \n535  positive  \n695  negative  \n557  negative  \n836  negative  \n","output_type":"stream"}]},{"cell_type":"markdown","source":"The line of code print(train_df['sentiment'].unique()) displays all the unique sentiment labels present in the 'sentiment' column of the train_df DataFrame. This is useful for:\n\nIdentifying Categories: Confirming the distinct sentiment classifications available in your dataset (e.g., 'positive', 'neutral', 'negative').\nChecking Data Integrity: Ensuring that the sentiment labels have been properly assigned and formatted without any unintended duplicates or whitespace.\nRunning this command helps you understand the range of sentiments your model will be working with during training and evaluation.","metadata":{}},{"cell_type":"code","source":"print(train_df['sentiment'].unique())\n","metadata":{"execution":{"iopub.status.busy":"2024-10-31T11:10:53.954512Z","iopub.execute_input":"2024-10-31T11:10:53.955666Z","iopub.status.idle":"2024-10-31T11:10:53.964480Z","shell.execute_reply.started":"2024-10-31T11:10:53.955629Z","shell.execute_reply":"2024-10-31T11:10:53.963458Z"},"trusted":true},"execution_count":67,"outputs":[{"name":"stdout","text":"['positive' 'negative' 'neutral']\n","output_type":"stream"}]},{"cell_type":"markdown","source":"This line of code performs two operations on the 'sentiment' column of the train_df DataFrame:\n\ntrain_df['sentiment'].str.strip(): This removes any leading or trailing whitespace from each sentiment label, ensuring that there are no extra spaces around the labels.\n\n.astype(str): This converts the cleaned sentiment labels to string type. This ensures that all entries in the 'sentiment' column are of the same type, which is important for consistency when processing or analyzing the data.\n\nBy executing this line, you ensure that the sentiment labels are correctly formatted and that all values are strings, making the data ready for further analysis or modeling tasks.","metadata":{}},{"cell_type":"code","source":"train_df['sentiment'] = train_df['sentiment'].str.strip().astype(str)\n","metadata":{"execution":{"iopub.status.busy":"2024-10-31T11:10:53.965865Z","iopub.execute_input":"2024-10-31T11:10:53.966159Z","iopub.status.idle":"2024-10-31T11:10:53.973683Z","shell.execute_reply.started":"2024-10-31T11:10:53.966128Z","shell.execute_reply":"2024-10-31T11:10:53.972766Z"},"trusted":true},"execution_count":68,"outputs":[]},{"cell_type":"markdown","source":"The line of code print(train_df['sentiment'].dtype) outputs the data type of the 'sentiment' column in the train_df DataFrame.\n\nIf the output shows dtype('O') or object, it confirms that the column contains string values, which is expected for sentiment labels.\nThis step is useful for verifying that the data type is correct after any preprocessing steps and ensuring consistency in the data format before proceeding with further analysis or model training","metadata":{}},{"cell_type":"code","source":"print(train_df['sentiment'].dtype)  # Should be 'object'\n","metadata":{"execution":{"iopub.status.busy":"2024-10-31T11:10:53.974681Z","iopub.execute_input":"2024-10-31T11:10:53.975428Z","iopub.status.idle":"2024-10-31T11:10:53.984019Z","shell.execute_reply.started":"2024-10-31T11:10:53.975392Z","shell.execute_reply":"2024-10-31T11:10:53.982996Z"},"trusted":true},"execution_count":69,"outputs":[{"name":"stdout","text":"object\n","output_type":"stream"}]},{"cell_type":"markdown","source":"This code creates a DataBlock object named kindle, which is designed for processing text data and preparing it for training a classification model. Here’s a breakdown of its components:\n\nDataBlock: A flexible way to define a data pipeline in fastai, specifying how to get data and what transformations to apply.\n\nblocks: This parameter defines the types of data blocks:\n\nTextBlock.from_df('reviewText', seq_len=72): This creates a text block from the reviewText column of a DataFrame, with sequences of length 72. This means that the text will be tokenized and padded or truncated to this length.\nCategoryBlock: This indicates that the target variable is categorical (in this case, the rating).\nget_y=ColReader('rating'): This specifies that the target labels (y-values) will be taken from the rating column of the DataFrame.\n\nsplitter=RandomSplitter(): This defines how to split the data into training and validation sets. The RandomSplitter will randomly divide the data, ensuring that both sets are representative of the overall dataset.\n\nThis kindle DataBlock can now be used to create data loaders for training and validating a text classification model.","metadata":{}},{"cell_type":"code","source":"kindle = DataBlock(\n    blocks=(TextBlock.from_df('reviewText', seq_len=72), CategoryBlock),\n    get_y=ColReader('rating'),  # Ensure 'rating' is a valid column\n    splitter=RandomSplitter()\n)","metadata":{"execution":{"iopub.status.busy":"2024-10-31T11:10:53.985251Z","iopub.execute_input":"2024-10-31T11:10:53.985620Z","iopub.status.idle":"2024-10-31T11:10:54.276727Z","shell.execute_reply.started":"2024-10-31T11:10:53.985583Z","shell.execute_reply":"2024-10-31T11:10:54.275670Z"},"trusted":true},"execution_count":70,"outputs":[]},{"cell_type":"markdown","source":"This code attempts to create data loaders from the kindle DataBlock using the train_df DataFrame, with a batch size of 32. Here's a breakdown of what happens:\n\ndls = kindle.dataloaders(train_df, bs=32): This line calls the dataloaders method on the kindle DataBlock to generate data loaders for the training and validation datasets. The bs=32 argument sets the batch size to 32, meaning that each batch will contain 32 samples.\n\ntry ... except Exception as e:: This structure is used to handle any potential errors that may occur during the creation of the data loaders. If an error occurs, it will be caught and printed.\n\nprint(f\"Error: {e}\"): If an exception is raised, this line will output the error message, allowing you to diagnose any issues that arise during the data loading process.\n\nRunning this code will either successfully create the data loaders or print an error message if something goes wrong, such as a mismatch in the expected column names or data types.","metadata":{}},{"cell_type":"code","source":"try:\n    dls = kindle.dataloaders(train_df, bs=32)\nexcept Exception as e:\n    print(f\"Error: {e}\")","metadata":{"execution":{"iopub.status.busy":"2024-10-31T11:10:54.278340Z","iopub.execute_input":"2024-10-31T11:10:54.278977Z","iopub.status.idle":"2024-10-31T11:10:55.955258Z","shell.execute_reply.started":"2024-10-31T11:10:54.278927Z","shell.execute_reply":"2024-10-31T11:10:55.953941Z"},"trusted":true},"execution_count":71,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n<style>\n    /* Turns off some styling */\n    progress {\n        /* gets rid of default border in Firefox and Opera. */\n        border: none;\n        /* Needs to be in here for Safari polyfill so background images work as expected. */\n        background-size: auto;\n    }\n    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n    }\n    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n        background: #F44336;\n    }\n</style>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"name":"stdout","text":"Error: unhashable type: 'L'\n","output_type":"stream"}]},{"cell_type":"markdown","source":"This code creates TextDataLoaders for language modeling from the train_df DataFrame and displays a sample batch:\n\nTextDataLoaders.from_df(...): Generates data loaders with the following settings:\n\ntext_col='reviewText': Uses the reviewText column for text.\nlabel_col='sentiment': Uses the sentiment column for labels.\nvalid_pct=0.1: Reserves 10% of the data for validation.\nbs=8: Sets the batch size to 8.\nseq_len=72: Limits sequence length to 72 tokens.\ndls_lm.show_batch(max_n=5): Displays up to 5 examples from the batch to verify the setup.\n\nThis process ensures the data loaders are configured correctly for training.","metadata":{}},{"cell_type":"code","source":"# Create TextDataLoaders from the DataFrame\ndls_lm = TextDataLoaders.from_df(\n    train_df, \n    text_col='reviewText', \n    label_col='sentiment', \n    valid_pct=0.1, \n    bs=8, \n    seq_len=72\n)\n\n# Display a batch to verify the setup\ndls_lm.show_batch(max_n=5)\n","metadata":{"execution":{"iopub.status.busy":"2024-10-31T11:10:55.957233Z","iopub.execute_input":"2024-10-31T11:10:55.957814Z","iopub.status.idle":"2024-10-31T11:10:58.138365Z","shell.execute_reply.started":"2024-10-31T11:10:55.957754Z","shell.execute_reply":"2024-10-31T11:10:58.137034Z"},"trusted":true},"execution_count":72,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n<style>\n    /* Turns off some styling */\n    progress {\n        /* gets rid of default border in Firefox and Opera. */\n        border: none;\n        /* Needs to be in here for Safari polyfill so background images work as expected. */\n        background-size: auto;\n    }\n    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n    }\n    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n        background: #F44336;\n    }\n</style>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>category</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>xxbos xxmaj i 've read several of xxmaj xxunk 's books over several series . xxmaj before reading this volume , i had read every other volume of this series ( except the xxunk 1 , vol . 7 ; it had not been published when i finished reading the other 5 ) . i had not read this one , because i did n't think the books needed to be read in sequence and the summary for this one just did n't interest me enough to want to read it . xxmaj since i thought 7 xxunk more than what i wanted to pay , and xxmaj i 'd been waiting for several months , a year at least i think , for her to finish the series , because vol . 6 actually ended with a cliff xxunk - i decided to just go ahead and read this</td>\n      <td>negative</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>xxbos xxmaj maybe xxmaj i 'm not as xxunk as the other reviewers , but i really did n't xxunk this hero . xxmaj maybe xxmaj i 'm xxunk and too romantic , but i really wish i had known that not 6 hours after taking h 's virginity , the hero would be xxunk his ex ( maybe not so ex ) xxunk i first started the book , i was enjoying the xxmaj xxunk xxmaj jones feel of the xxunk , awkward heroine , but the hero was no xxmaj mr . xxmaj xxunk . xxmaj when h first meets xxup h , he 's wearing a xxunk that xxunk xxmaj xxunk xxmaj no xxmaj xxunk . xxmaj what guy wears that ? i had to check to make sure this guy was really the xxup h. xxmaj he 's cold and even mean to her in the</td>\n      <td>negative</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>xxbos * * possible xxmaj spoilers * * xxmaj if i had to review this book in one word it would be ' ridiculous ' . i had high hopes the first few pages as the initial crime xxunk . i went into it willing to suspend belief about a xxunk using that xxunk as a cover for her real job as a xxup cia agent . xxmaj when i read xxmaj jaclyn 's back story about her parents and her near xxunk i thought , \" h xxrep 3 m … this is intriguing . xxunk too long though it became xxunk that this book was going to xxunk due to xxunk xxunk guys , silly xxunk type xxunk , and a plot whose xxunk you could xxunk a plane xxunk could have been an interesting thriller was anything but . xxmaj the villain of the piece was presented</td>\n      <td>negative</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>xxbos xxmaj you xxmaj can xxmaj leave xxmaj your xxmaj xxunk xxmaj on is what the title promised , a naughty little novella on a stripper and his lover . xxmaj the starting point of the story is one i already see in the past , a young and handsome xxmaj college xxup xxunk , xxmaj harlan , who has the xxunk for his even more handsome , a slightly older , xxmaj college professor , xxmaj sawyer . xxmaj the book xxunk the rules of a xxmaj may / xxmaj xxunk romance plus the xxmaj college setting with an xxmaj office xxmaj xxunk theme … the xxunk the thing , this is the xxunk romance by the rule , with the twist of being a gay romance . xxmaj so i would say that it can appeal both to the old fan of the gay romance than to a</td>\n      <td>positive</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>xxbos xxmaj xxunk xxmaj property by xxmaj leah xxmaj xxunk is the first book in the xxmaj xxunk xxmaj security series . xxmaj it is also xxmaj leah 's first published work and i enjoyed it so much i knew xxmaj i 'd read anything future she published . xxmaj the characters are interesting , the dialog engaging , and the sex scenes are hot . xxmaj what truly xxunk me though was the fact that this book takes place less than a half of a xxunk from my home and she described it xxunk book xxunk around xxmaj mark xxmaj xxunk and xxmaj jodi xxmaj xxunk . xxmaj mark is the owner of xxmaj xxunk xxmaj security xxunk in xxmaj texas and xxmaj jodi one of his xxunk . xxmaj the book xxunk with xxmaj jodi xxunk out a home she is suppose to break into to prove to</td>\n      <td>positive</td>\n    </tr>\n  </tbody>\n</table>"},"metadata":{}}]},{"cell_type":"markdown","source":"This code snippet sets an environment variable to configure CUDA memory allocation for PyTorch:\n\nimport os: Imports the operating system module, which allows interaction with the system’s environment variables.\n\nos.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'expandable_segments:True': This line sets the PYTORCH_CUDA_ALLOC_CONF environment variable to enable expandable segments in CUDA memory allocation. This configuration can help optimize GPU memory usage by allowing PyTorch to expand memory segments as needed, potentially reducing fragmentation and improving performance during model training or inference on GPUs.\n\nOverall, this setup is useful when working with deep learning models in PyTorch on a GPU to enhance memory management.","metadata":{}},{"cell_type":"code","source":"import os\n\n\n# Set the environment variable for CUDA allocation\nos.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'expandable_segments:True'","metadata":{"execution":{"iopub.status.busy":"2024-10-31T11:10:58.140345Z","iopub.execute_input":"2024-10-31T11:10:58.141101Z","iopub.status.idle":"2024-10-31T11:10:58.146694Z","shell.execute_reply.started":"2024-10-31T11:10:58.141031Z","shell.execute_reply":"2024-10-31T11:10:58.145552Z"},"trusted":true},"execution_count":73,"outputs":[]},{"cell_type":"markdown","source":"This code provides insights into the train_df DataFrame by performing three operations:\n\nprint(train_df.shape): This command outputs the dimensions of the DataFrame, showing the number of rows and columns (e.g., (num_rows, num_columns)).\n\nprint(train_df.info()): This line displays a summary of the DataFrame, including the data types of each column, the number of non-null values, and memory usage. This information is useful for understanding the structure and completeness of the data.\n\nprint(train_df.head()): This command shows the first five rows of the DataFrame, allowing you to quickly inspect the data and see how the reviews and sentiment labels are structured.\n\nTogether, these commands help you verify the dataset's shape, understand its structure, and visually inspect the data.","metadata":{}},{"cell_type":"code","source":"print(train_df.shape)  # Check the number of rows and columns\nprint(train_df.info())  # Get info on data types\nprint(train_df.head())  # View the first few rows\n","metadata":{"execution":{"iopub.status.busy":"2024-10-31T11:10:58.148144Z","iopub.execute_input":"2024-10-31T11:10:58.149098Z","iopub.status.idle":"2024-10-31T11:10:58.169637Z","shell.execute_reply.started":"2024-10-31T11:10:58.149046Z","shell.execute_reply":"2024-10-31T11:10:58.168561Z"},"trusted":true},"execution_count":74,"outputs":[{"name":"stdout","text":"(800, 5)\n<class 'pandas.core.frame.DataFrame'>\nIndex: 800 entries, 29 to 102\nData columns (total 5 columns):\n #   Column      Non-Null Count  Dtype \n---  ------      --------------  ----- \n 0   Unnamed: 0  800 non-null    int64 \n 1   rating      800 non-null    int64 \n 2   reviewText  800 non-null    object\n 3   summary     800 non-null    object\n 4   sentiment   800 non-null    object\ndtypes: int64(2), object(3)\nmemory usage: 37.5+ KB\nNone\n     Unnamed: 0  rating  \\\n29           29       5   \n535         535       4   \n695         695       1   \n557         557       1   \n836         836       2   \n\n                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  reviewText  \\\n29   I have read tons of books, and this is one of the best books I've ever read! Imagine the concept of a hitch-hiking serial killer being picked up by a serial killer! It's hilarious! I've read all the versions and prequels and sequels that Kilborn and Crouch wrote about these characters, and let me tell you they are all great! They have some really twisted minds, and I love that. Kinda reminds me of myself lol. Keep it up you two, because I want to read more of your stuff! And don't ever hitchhike!!!   \n535                                                                                                                                                                                                                                                                                                                                       A great read. Nate and Emery's story was sweet. I really enjoyed the book from start to finish.  The electricity involved between them was epic. We need a few more men like Nate.   \n695                                                                                                                                                                                                                                                                                                                                               Ok I bought this because it was free and thought a cute short story - half way through it does this weird twist and I started laughing.  Not streamy but stupid - skip it.   \n557                                                                                                                                                                                                                                                                                                                                                                                   Poorly written.  Good story.  Needs editor.  Rambles.  I would avoid the work--but give the author another chance should he try again.   \n836                                                                                                                                                                                                                                                                                      This book is not one of my faviourties, but that may be because I was not expecting the unexpected, I did read the whole book and enjoyed the story line and some of the quirky lines, and the story flowed.sorry it is me not you.   \n\n                               summary sentiment  \n29            The greatest story ever!  positive  \n535                             Great.  positive  \n695  Don't Buy - even though it's free  negative  \n557               Close --But No Cigar  negative  \n836                         Blind Date  negative  \n","output_type":"stream"}]},{"cell_type":"markdown","source":"This code performs two checks on the train_df DataFrame:\n\nprint(train_df['reviewText'].isnull().sum()): This command calculates and prints the total number of null (missing) values in the 'reviewText' column. This check is important to ensure that there are no missing reviews that could affect model training or evaluation.\n\nprint(train_df['sentiment'].unique()): This line retrieves and prints the unique values present in the 'sentiment' column. This helps you verify the distinct sentiment categories (e.g., 'positive', 'neutral', 'negative') and ensures that the sentiment labels are correctly assigned without duplicates or unexpected values.\n\nTogether, these commands help assess the quality of the data in the DataFrame before proceeding with further analysis or modeling.","metadata":{}},{"cell_type":"code","source":"print(train_df['reviewText'].isnull().sum())  # Check for nulls in text column\nprint(train_df['sentiment'].unique())  # Check unique values in sentiment column\n","metadata":{"execution":{"iopub.status.busy":"2024-10-31T11:10:58.171146Z","iopub.execute_input":"2024-10-31T11:10:58.171920Z","iopub.status.idle":"2024-10-31T11:10:58.180357Z","shell.execute_reply.started":"2024-10-31T11:10:58.171854Z","shell.execute_reply":"2024-10-31T11:10:58.179344Z"},"trusted":true},"execution_count":75,"outputs":[{"name":"stdout","text":"0\n['positive' 'negative' 'neutral']\n","output_type":"stream"}]},{"cell_type":"code","source":"print(train_df['sentiment'].unique()) ","metadata":{"execution":{"iopub.status.busy":"2024-10-31T11:10:58.181792Z","iopub.execute_input":"2024-10-31T11:10:58.182419Z","iopub.status.idle":"2024-10-31T11:10:58.189567Z","shell.execute_reply.started":"2024-10-31T11:10:58.182367Z","shell.execute_reply":"2024-10-31T11:10:58.188437Z"},"trusted":true},"execution_count":76,"outputs":[{"name":"stdout","text":"['positive' 'negative' 'neutral']\n","output_type":"stream"}]},{"cell_type":"code","source":"# Convert sentiment to categorical\ntrain_df['sentiment'] = train_df['sentiment'].astype('category')","metadata":{"execution":{"iopub.status.busy":"2024-10-31T11:10:58.197007Z","iopub.execute_input":"2024-10-31T11:10:58.197307Z","iopub.status.idle":"2024-10-31T11:10:58.202867Z","shell.execute_reply.started":"2024-10-31T11:10:58.197276Z","shell.execute_reply":"2024-10-31T11:10:58.201793Z"},"trusted":true},"execution_count":77,"outputs":[]},{"cell_type":"code","source":"print(train_df.info())\nprint(train_df['sentiment'].unique())","metadata":{"execution":{"iopub.status.busy":"2024-10-31T11:10:58.204471Z","iopub.execute_input":"2024-10-31T11:10:58.204893Z","iopub.status.idle":"2024-10-31T11:10:58.219686Z","shell.execute_reply.started":"2024-10-31T11:10:58.204847Z","shell.execute_reply":"2024-10-31T11:10:58.218671Z"},"trusted":true},"execution_count":78,"outputs":[{"name":"stdout","text":"<class 'pandas.core.frame.DataFrame'>\nIndex: 800 entries, 29 to 102\nData columns (total 5 columns):\n #   Column      Non-Null Count  Dtype   \n---  ------      --------------  -----   \n 0   Unnamed: 0  800 non-null    int64   \n 1   rating      800 non-null    int64   \n 2   reviewText  800 non-null    object  \n 3   summary     800 non-null    object  \n 4   sentiment   800 non-null    category\ndtypes: category(1), int64(2), object(2)\nmemory usage: 32.2+ KB\nNone\n['positive', 'negative', 'neutral']\nCategories (3, object): ['negative', 'neutral', 'positive']\n","output_type":"stream"}]},{"cell_type":"code","source":"# Creating DataLoaders with adjusted sequence length and batch size\ndls_lm = TextDataLoaders.from_df(\n    train_df, \n    text_col='reviewText', \n    label_col='sentiment', \n    valid_pct=0.1, \n    bs=16,  # Adjust batch size\n    seq_len=512  # Adjust sequence length\n)\n\n# Check the DataLoader output again\nfor x, y in dls_lm.train:\n    print(f\"Input shape: {x.shape}, Target shape: {y.shape}\")\n    break  # Check only the first batch\n\n","metadata":{"execution":{"iopub.status.busy":"2024-10-31T11:10:58.221148Z","iopub.execute_input":"2024-10-31T11:10:58.221692Z","iopub.status.idle":"2024-10-31T11:11:00.450961Z","shell.execute_reply.started":"2024-10-31T11:10:58.221644Z","shell.execute_reply":"2024-10-31T11:11:00.449677Z"},"trusted":true},"execution_count":79,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n<style>\n    /* Turns off some styling */\n    progress {\n        /* gets rid of default border in Firefox and Opera. */\n        border: none;\n        /* Needs to be in here for Safari polyfill so background images work as expected. */\n        background-size: auto;\n    }\n    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n    }\n    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n        background: #F44336;\n    }\n</style>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"name":"stdout","text":"Input shape: torch.Size([16, 1752]), Target shape: torch.Size([16])\n","output_type":"stream"}]},{"cell_type":"code","source":"# Proceed with model training\nlearn = text_classifier_learner(dls_lm, AWD_LSTM, metrics=accuracy).to_fp16()\n\ntry:\n    learn.fit_one_cycle(1, 1e-10)\nexcept Exception as e:\n    print(f\"Training error: {e}\")","metadata":{"execution":{"iopub.status.busy":"2024-10-31T11:11:00.452948Z","iopub.execute_input":"2024-10-31T11:11:00.453404Z","iopub.status.idle":"2024-10-31T11:11:03.597656Z","shell.execute_reply.started":"2024-10-31T11:11:00.453353Z","shell.execute_reply":"2024-10-31T11:11:03.596568Z"},"trusted":true},"execution_count":80,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/fastai/text/learner.py:149: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  wgts = torch.load(wgts_fname, map_location = lambda storage,loc: storage)\n/opt/conda/lib/python3.10/site-packages/fastai/callback/fp16.py:47: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  self.autocast,self.learn.scaler,self.scales = autocast(dtype=dtype),GradScaler(**self.kwargs),L()\n/opt/conda/lib/python3.10/site-packages/fastai/callback/fp16.py:47: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n  self.autocast,self.learn.scaler,self.scales = autocast(dtype=dtype),GradScaler(**self.kwargs),L()\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n<style>\n    /* Turns off some styling */\n    progress {\n        /* gets rid of default border in Firefox and Opera. */\n        border: none;\n        /* Needs to be in here for Safari polyfill so background images work as expected. */\n        background-size: auto;\n    }\n    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n    }\n    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n        background: #F44336;\n    }\n</style>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: left;\">\n      <th>epoch</th>\n      <th>train_loss</th>\n      <th>valid_loss</th>\n      <th>accuracy</th>\n      <th>time</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>0</td>\n      <td>1.203790</td>\n      <td>1.340273</td>\n      <td>0.187500</td>\n      <td>00:02</td>\n    </tr>\n  </tbody>\n</table>"},"metadata":{}}]},{"cell_type":"code","source":"learn.save('1epoch')","metadata":{"execution":{"iopub.status.busy":"2024-10-31T11:11:03.599451Z","iopub.execute_input":"2024-10-31T11:11:03.599868Z","iopub.status.idle":"2024-10-31T11:11:03.835450Z","shell.execute_reply.started":"2024-10-31T11:11:03.599820Z","shell.execute_reply":"2024-10-31T11:11:03.834349Z"},"trusted":true},"execution_count":81,"outputs":[{"execution_count":81,"output_type":"execute_result","data":{"text/plain":"Path('models/1epoch.pth')"},"metadata":{}}]},{"cell_type":"code","source":"learn = learn.load('1epoch')","metadata":{"execution":{"iopub.status.busy":"2024-10-31T11:11:03.837142Z","iopub.execute_input":"2024-10-31T11:11:03.837977Z","iopub.status.idle":"2024-10-31T11:11:03.893332Z","shell.execute_reply.started":"2024-10-31T11:11:03.837922Z","shell.execute_reply":"2024-10-31T11:11:03.892249Z"},"trusted":true},"execution_count":82,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/fastai/text/learner.py:92: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  state = torch.load(file, map_location=device)\n","output_type":"stream"}]},{"cell_type":"markdown","source":"This code snippet is used to train a text classification model using the fastai library. Here's a brief explanation of each step:\n\nlearn.freeze(): This command freezes all layers of the model except for the last layer. This allows you to start training with only the last layer being updated, which helps the model adapt to the new data without drastically altering the learned features from the pre-trained model.\n\nlearn.fit_one_cycle(10, 1e-3): This method trains the model for 10 epochs using the one-cycle learning rate policy with a learning rate of \n1\n×\n1\n0\n−\n3\n1×10 \n−3\n . The one-cycle policy helps improve convergence by adjusting the learning rate throughout the training process.\n\nlearn.unfreeze(): This command unfreezes all layers of the model, allowing all weights to be updated during training. This is done after the initial training to further refine the model's performance.\n\nlearn.fit_one_cycle(10, 1e-3): This line continues training for another 10 epochs using the same one-cycle learning rate policy and learning rate. By unfreezing the layers, the model can fine-tune all its parameters for improved accuracy on the training data.\n\nThis approach helps achieve better model performance by gradually unfreezing layers and allowing the model to adapt to the specific characteristics of the training data.","metadata":{}},{"cell_type":"code","source":"learn.freeze()  # Start with only the last layer trained\nlearn.fit_one_cycle(10, 1e-3)  # First few epochs\n\nlearn.unfreeze()  # Then unfreeze and train further\nlearn.fit_one_cycle(10, 1e-3)  # Continue training\n","metadata":{"execution":{"iopub.status.busy":"2024-10-31T11:11:03.894605Z","iopub.execute_input":"2024-10-31T11:11:03.894943Z","iopub.status.idle":"2024-10-31T11:12:15.521782Z","shell.execute_reply.started":"2024-10-31T11:11:03.894906Z","shell.execute_reply":"2024-10-31T11:12:15.520579Z"},"trusted":true},"execution_count":83,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/fastai/callback/fp16.py:47: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  self.autocast,self.learn.scaler,self.scales = autocast(dtype=dtype),GradScaler(**self.kwargs),L()\n/opt/conda/lib/python3.10/site-packages/fastai/callback/fp16.py:47: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n  self.autocast,self.learn.scaler,self.scales = autocast(dtype=dtype),GradScaler(**self.kwargs),L()\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n<style>\n    /* Turns off some styling */\n    progress {\n        /* gets rid of default border in Firefox and Opera. */\n        border: none;\n        /* Needs to be in here for Safari polyfill so background images work as expected. */\n        background-size: auto;\n    }\n    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n    }\n    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n        background: #F44336;\n    }\n</style>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: left;\">\n      <th>epoch</th>\n      <th>train_loss</th>\n      <th>valid_loss</th>\n      <th>accuracy</th>\n      <th>time</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>0</td>\n      <td>1.142257</td>\n      <td>1.255343</td>\n      <td>0.375000</td>\n      <td>00:02</td>\n    </tr>\n    <tr>\n      <td>1</td>\n      <td>1.013957</td>\n      <td>1.046468</td>\n      <td>0.550000</td>\n      <td>00:02</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.890927</td>\n      <td>0.970777</td>\n      <td>0.587500</td>\n      <td>00:02</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.833328</td>\n      <td>1.017013</td>\n      <td>0.612500</td>\n      <td>00:02</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>0.751557</td>\n      <td>0.930158</td>\n      <td>0.587500</td>\n      <td>00:02</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>0.696884</td>\n      <td>0.953884</td>\n      <td>0.600000</td>\n      <td>00:02</td>\n    </tr>\n    <tr>\n      <td>6</td>\n      <td>0.642602</td>\n      <td>0.990832</td>\n      <td>0.612500</td>\n      <td>00:02</td>\n    </tr>\n    <tr>\n      <td>7</td>\n      <td>0.603222</td>\n      <td>0.984389</td>\n      <td>0.625000</td>\n      <td>00:02</td>\n    </tr>\n    <tr>\n      <td>8</td>\n      <td>0.578702</td>\n      <td>0.947767</td>\n      <td>0.662500</td>\n      <td>00:02</td>\n    </tr>\n    <tr>\n      <td>9</td>\n      <td>0.593789</td>\n      <td>0.969114</td>\n      <td>0.587500</td>\n      <td>00:02</td>\n    </tr>\n  </tbody>\n</table>"},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/fastai/callback/fp16.py:47: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  self.autocast,self.learn.scaler,self.scales = autocast(dtype=dtype),GradScaler(**self.kwargs),L()\n/opt/conda/lib/python3.10/site-packages/fastai/callback/fp16.py:47: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n  self.autocast,self.learn.scaler,self.scales = autocast(dtype=dtype),GradScaler(**self.kwargs),L()\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n<style>\n    /* Turns off some styling */\n    progress {\n        /* gets rid of default border in Firefox and Opera. */\n        border: none;\n        /* Needs to be in here for Safari polyfill so background images work as expected. */\n        background-size: auto;\n    }\n    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n    }\n    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n        background: #F44336;\n    }\n</style>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: left;\">\n      <th>epoch</th>\n      <th>train_loss</th>\n      <th>valid_loss</th>\n      <th>accuracy</th>\n      <th>time</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>0</td>\n      <td>0.601469</td>\n      <td>0.942005</td>\n      <td>0.612500</td>\n      <td>00:04</td>\n    </tr>\n    <tr>\n      <td>1</td>\n      <td>0.596118</td>\n      <td>1.515004</td>\n      <td>0.512500</td>\n      <td>00:04</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.478844</td>\n      <td>1.058623</td>\n      <td>0.612500</td>\n      <td>00:04</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.356782</td>\n      <td>1.071256</td>\n      <td>0.612500</td>\n      <td>00:04</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>0.258383</td>\n      <td>1.223911</td>\n      <td>0.650000</td>\n      <td>00:04</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>0.182588</td>\n      <td>0.997650</td>\n      <td>0.712500</td>\n      <td>00:04</td>\n    </tr>\n    <tr>\n      <td>6</td>\n      <td>0.124444</td>\n      <td>1.014282</td>\n      <td>0.725000</td>\n      <td>00:04</td>\n    </tr>\n    <tr>\n      <td>7</td>\n      <td>0.085674</td>\n      <td>0.934991</td>\n      <td>0.700000</td>\n      <td>00:04</td>\n    </tr>\n    <tr>\n      <td>8</td>\n      <td>0.062532</td>\n      <td>0.934879</td>\n      <td>0.737500</td>\n      <td>00:04</td>\n    </tr>\n    <tr>\n      <td>9</td>\n      <td>0.052266</td>\n      <td>0.968528</td>\n      <td>0.700000</td>\n      <td>00:04</td>\n    </tr>\n  </tbody>\n</table>"},"metadata":{}}]},{"cell_type":"markdown","source":"The command learn.save_encoder('finetuned') saves the encoder part of the model after fine-tuning. This allows you to preserve the learned features for future use or transfer learning, enabling quicker retraining or application to similar tasks without starting from scratch.","metadata":{}},{"cell_type":"code","source":"learn.save_encoder('finetuned')","metadata":{"execution":{"iopub.status.busy":"2024-10-31T11:12:15.523725Z","iopub.execute_input":"2024-10-31T11:12:15.524583Z","iopub.status.idle":"2024-10-31T11:12:15.757506Z","shell.execute_reply.started":"2024-10-31T11:12:15.524524Z","shell.execute_reply":"2024-10-31T11:12:15.756445Z"},"trusted":true},"execution_count":84,"outputs":[]},{"cell_type":"markdown","source":"This code snippet retrieves the predictions made by the model and the actual target labels from the validation set:\n\npreds, targets = learn.get_preds(): This command generates predictions (preds) and the corresponding target labels (targets) from the validation dataset. The predictions are typically in the form of probabilities for each class, while the targets are the true labels.\n\nprint(preds): This line prints the predicted values. Depending on the model's output configuration, this might show probabilities for each class, which can later be used for calculating metrics like accuracy, precision, recall, or for further analysis.\n\nTogether, these commands are useful for evaluating the model's performance and understanding how well it is making predictions on unseen data.","metadata":{}},{"cell_type":"code","source":"preds, targets = learn.get_preds()\nprint(preds)","metadata":{"execution":{"iopub.status.busy":"2024-10-31T11:12:15.759322Z","iopub.execute_input":"2024-10-31T11:12:15.759727Z","iopub.status.idle":"2024-10-31T11:12:16.363458Z","shell.execute_reply.started":"2024-10-31T11:12:15.759682Z","shell.execute_reply":"2024-10-31T11:12:16.362224Z"},"trusted":true},"execution_count":85,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/fastai/callback/fp16.py:47: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  self.autocast,self.learn.scaler,self.scales = autocast(dtype=dtype),GradScaler(**self.kwargs),L()\n/opt/conda/lib/python3.10/site-packages/fastai/callback/fp16.py:47: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n  self.autocast,self.learn.scaler,self.scales = autocast(dtype=dtype),GradScaler(**self.kwargs),L()\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n<style>\n    /* Turns off some styling */\n    progress {\n        /* gets rid of default border in Firefox and Opera. */\n        border: none;\n        /* Needs to be in here for Safari polyfill so background images work as expected. */\n        background-size: auto;\n    }\n    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n    }\n    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n        background: #F44336;\n    }\n</style>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"name":"stdout","text":"tensor([[8.9323e-01, 1.0269e-01, 4.0724e-03],\n        [2.5934e-03, 3.5444e-02, 9.6196e-01],\n        [2.4612e-01, 5.8497e-01, 1.6891e-01],\n        [2.3184e-01, 4.2777e-01, 3.4039e-01],\n        [6.9884e-04, 3.6617e-03, 9.9564e-01],\n        [8.7576e-01, 4.3136e-02, 8.1101e-02],\n        [9.2207e-01, 1.7942e-02, 5.9991e-02],\n        [9.4673e-01, 4.9207e-02, 4.0627e-03],\n        [1.6987e-02, 1.0748e-01, 8.7554e-01],\n        [9.8136e-01, 1.7430e-02, 1.2066e-03],\n        [2.4261e-02, 2.6950e-01, 7.0624e-01],\n        [3.5156e-02, 4.0570e-01, 5.5915e-01],\n        [7.3417e-01, 1.0868e-02, 2.5496e-01],\n        [5.3366e-01, 1.7800e-03, 4.6456e-01],\n        [3.5508e-01, 1.9451e-03, 6.4297e-01],\n        [2.5681e-02, 1.4277e-01, 8.3155e-01],\n        [9.7965e-01, 1.4291e-02, 6.0573e-03],\n        [2.5803e-03, 5.7601e-01, 4.2141e-01],\n        [4.8042e-01, 1.6281e-01, 3.5678e-01],\n        [1.4951e-01, 2.0360e-02, 8.3013e-01],\n        [9.0032e-02, 3.2346e-01, 5.8651e-01],\n        [3.5634e-03, 1.8008e-02, 9.7843e-01],\n        [1.6186e-05, 8.6651e-05, 9.9990e-01],\n        [1.1967e-01, 4.9241e-01, 3.8792e-01],\n        [7.6008e-01, 9.6162e-02, 1.4376e-01],\n        [6.0739e-02, 3.4961e-01, 5.8965e-01],\n        [9.7448e-01, 9.1338e-03, 1.6386e-02],\n        [8.4257e-05, 6.5290e-03, 9.9339e-01],\n        [4.8557e-02, 6.3423e-02, 8.8802e-01],\n        [9.4520e-01, 3.1548e-02, 2.3250e-02],\n        [9.6926e-04, 1.7904e-02, 9.8113e-01],\n        [9.7750e-02, 4.6089e-02, 8.5616e-01],\n        [2.9400e-04, 5.0034e-01, 4.9936e-01],\n        [2.4531e-01, 6.1898e-01, 1.3571e-01],\n        [1.0810e-02, 7.5244e-03, 9.8167e-01],\n        [1.3702e-02, 7.1496e-02, 9.1480e-01],\n        [4.9769e-01, 9.4601e-03, 4.9285e-01],\n        [3.5626e-05, 1.9890e-04, 9.9977e-01],\n        [1.7745e-03, 5.5366e-02, 9.4286e-01],\n        [9.6926e-04, 1.7904e-02, 9.8113e-01],\n        [1.8804e-03, 6.7650e-03, 9.9135e-01],\n        [1.7388e-01, 1.8588e-02, 8.0754e-01],\n        [2.8879e-02, 2.5657e-03, 9.6856e-01],\n        [3.8112e-03, 4.2779e-01, 5.6840e-01],\n        [6.9482e-01, 1.2700e-01, 1.7817e-01],\n        [1.1364e-01, 8.7938e-01, 6.9816e-03],\n        [8.6430e-01, 1.5954e-02, 1.1974e-01],\n        [2.7653e-01, 6.1935e-03, 7.1727e-01],\n        [2.7820e-01, 6.6135e-02, 6.5566e-01],\n        [7.6137e-03, 4.3246e-01, 5.5992e-01],\n        [1.9406e-01, 1.8273e-02, 7.8766e-01],\n        [2.3729e-03, 2.2118e-03, 9.9542e-01],\n        [1.9093e-03, 1.2902e-02, 9.8519e-01],\n        [6.0499e-01, 1.1989e-01, 2.7513e-01],\n        [1.3640e-02, 1.7239e-03, 9.8464e-01],\n        [3.5698e-01, 1.6819e-02, 6.2621e-01],\n        [9.6926e-04, 1.7904e-02, 9.8113e-01],\n        [8.4781e-02, 2.4631e-02, 8.9059e-01],\n        [5.4967e-03, 1.0203e-01, 8.9247e-01],\n        [9.6926e-04, 1.7904e-02, 9.8113e-01],\n        [6.7872e-03, 8.2754e-03, 9.8494e-01],\n        [1.4909e-03, 1.0745e-02, 9.8776e-01],\n        [1.2951e-02, 6.7749e-03, 9.8027e-01],\n        [9.8179e-01, 1.6001e-02, 2.2072e-03],\n        [9.7840e-01, 2.8520e-03, 1.8748e-02],\n        [9.6265e-01, 3.7908e-03, 3.3561e-02],\n        [9.3389e-02, 4.0660e-02, 8.6595e-01],\n        [5.3426e-01, 4.6508e-01, 6.5175e-04],\n        [1.9089e-01, 4.4670e-02, 7.6444e-01],\n        [8.5478e-03, 4.4302e-03, 9.8702e-01],\n        [1.5105e-05, 2.2116e-02, 9.7787e-01],\n        [7.8083e-01, 1.8537e-01, 3.3792e-02],\n        [9.9654e-01, 3.0030e-03, 4.6052e-04],\n        [6.7608e-02, 1.1282e-02, 9.2111e-01],\n        [8.8017e-01, 5.0759e-02, 6.9075e-02],\n        [3.1784e-01, 1.1921e-02, 6.7024e-01],\n        [2.9622e-04, 4.9591e-03, 9.9474e-01],\n        [6.5164e-01, 1.4346e-01, 2.0490e-01],\n        [2.9052e-01, 1.1071e-01, 5.9877e-01],\n        [9.1158e-01, 4.0228e-02, 4.8194e-02]])\n","output_type":"stream"}]},{"cell_type":"markdown","source":"This code snippet is used to create an interpretation object for a classification model and visualize its performance through a confusion matrix. Here’s a breakdown of each step:\n\nCreating an Interpretation Object:\n\ninterp = ClassificationInterpretation.from_learner(learn): This command creates an interpretation object from the trained model (learn). This object helps analyze the model's predictions and errors, providing insights into its performance.\nPlotting the Confusion Matrix:\n\ninterp.plot_confusion_matrix(): This method generates and displays a confusion matrix based on the model's predictions and the true labels. The confusion matrix shows how many instances of each class were correctly classified versus misclassified, allowing you to visually assess where the model is performing well and where it might be making mistakes.\nOverall, these steps are useful for diagnosing the model's performance and understanding the specific areas for improvement in its classification tasks.","metadata":{}},{"cell_type":"code","source":"# Step 1: Create an interpretation object\ninterp = ClassificationInterpretation.from_learner(learn)\n\n# Step 2: Plot the confusion matrix\ninterp.plot_confusion_matrix()","metadata":{"execution":{"iopub.status.busy":"2024-10-31T11:12:16.365598Z","iopub.execute_input":"2024-10-31T11:12:16.366352Z","iopub.status.idle":"2024-10-31T11:12:18.069798Z","shell.execute_reply.started":"2024-10-31T11:12:16.366289Z","shell.execute_reply":"2024-10-31T11:12:18.068673Z"},"trusted":true},"execution_count":86,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/fastai/callback/fp16.py:47: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  self.autocast,self.learn.scaler,self.scales = autocast(dtype=dtype),GradScaler(**self.kwargs),L()\n/opt/conda/lib/python3.10/site-packages/fastai/callback/fp16.py:47: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n  self.autocast,self.learn.scaler,self.scales = autocast(dtype=dtype),GradScaler(**self.kwargs),L()\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n<style>\n    /* Turns off some styling */\n    progress {\n        /* gets rid of default border in Firefox and Opera. */\n        border: none;\n        /* Needs to be in here for Safari polyfill so background images work as expected. */\n        background-size: auto;\n    }\n    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n    }\n    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n        background: #F44336;\n    }\n</style>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/fastai/callback/fp16.py:47: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  self.autocast,self.learn.scaler,self.scales = autocast(dtype=dtype),GradScaler(**self.kwargs),L()\n/opt/conda/lib/python3.10/site-packages/fastai/callback/fp16.py:47: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n  self.autocast,self.learn.scaler,self.scales = autocast(dtype=dtype),GradScaler(**self.kwargs),L()\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n<style>\n    /* Turns off some styling */\n    progress {\n        /* gets rid of default border in Firefox and Opera. */\n        border: none;\n        /* Needs to be in here for Safari polyfill so background images work as expected. */\n        background-size: auto;\n    }\n    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n    }\n    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n        background: #F44336;\n    }\n</style>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<Figure size 640x480 with 1 Axes>","image/png":"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"},"metadata":{}}]},{"cell_type":"markdown","source":"The result shows there  are only 8  true neutral  statements  which  we  cannot see due to the fact that  two negative make a positive and one positive negative is considered  nnegative like not  bad  means good  but for  a  machine  it is more like a negative  word.","metadata":{}},{"cell_type":"markdown","source":"This code generates a classification report to evaluate a model's performance:\n\nConvert Predictions: It converts the predicted probabilities (preds) to predicted labels using torch.argmax() and also converts the actual targets to NumPy arrays.\nGenerate Report: The classification_report function computes precision, recall, F1-score, and support for each sentiment class ('negative', 'neutral', 'positive').\nPrint Report: Finally, it prints the classification report, providing insights into the model's performance.","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import classification_report\nimport torch\n\n# Assuming `preds` and `targets` are tensor objects, convert them to numpy arrays\npreds_numpy = torch.argmax(preds, axis=1).numpy()  # Convert predicted probabilities to predicted labels\ntargets_numpy = targets.numpy()\n\n# Generate the classification report\nreport = classification_report(targets_numpy, preds_numpy, target_names=['negative', 'neutral', 'positive'])\n\n# Print the report\nprint(report)","metadata":{"execution":{"iopub.status.busy":"2024-10-31T11:12:18.071808Z","iopub.execute_input":"2024-10-31T11:12:18.072449Z","iopub.status.idle":"2024-10-31T11:12:18.091095Z","shell.execute_reply.started":"2024-10-31T11:12:18.072398Z","shell.execute_reply":"2024-10-31T11:12:18.090179Z"},"trusted":true},"execution_count":87,"outputs":[{"name":"stdout","text":"              precision    recall  f1-score   support\n\n    negative       0.64      0.84      0.73        19\n     neutral       0.43      0.19      0.26        16\n    positive       0.77      0.82      0.80        45\n\n    accuracy                           0.70        80\n   macro avg       0.61      0.62      0.59        80\nweighted avg       0.67      0.70      0.67        80\n\n","output_type":"stream"}]},{"cell_type":"markdown","source":"This classification report summarizes the performance of a sentiment classification model across three categories: negative, neutral, and positive. Here's a brief explanation of each metric:\n\nPrecision: Measures the accuracy of positive predictions. For example:\n\nNegative: 0.90 means 90% of predicted negatives were correct.\nNeutral: 0.00 indicates no neutral predictions were correct.\nPositive: 0.74 means 74% of predicted positives were correct.\nRecall: Measures the ability to find all relevant instances. For example:\n\nNegative: 0.78 means 78% of actual negatives were correctly identified.\nNeutral: 0.00 indicates none of the actual neutrals were identified.\nPositive: 0.86 means 86% of actual positives were correctly identified.\nF1-Score: The harmonic mean of precision and recall, providing a balance between the two:\n\nNegative: 0.84\nNeutral: 0.00 (indicating poor performance)\nPositive: 0.79\nSupport: The number of actual occurrences of each class in the specified dataset:\n\nNegative: 36 instances\nNeutral: 8 instances\nPositive: 36 instances\nAccuracy: Overall, the model correctly predicted 74% of the instances in the dataset (accuracy of 0.74).\n\nMacro Average: Averages the precision, recall, and F1-score across all classes without considering class imbalance (resulting in lower scores due to the neutral class).\n\nWeighted Average: Averages the precision, recall, and F1-score while considering the support of each class, providing a more representative score of the model's performance overall.\n\nOverall, the model performs well for negative and positive sentiments but struggles significantly with neutral sentiment.","metadata":{}},{"cell_type":"markdown","source":"This code generates multiple sentences based on an initial text using a trained model:\n\nInitialize: An empty list predictions is created to store generated reviews and sentiments.\nGenerate Sentences: For a specified number of sentences, it predicts new text and sentiment, appending the results to the list.\nCreate DataFrame: A Pandas DataFrame predictions_df is created from the predictions.\nPrint Results: The generated reviews and sentiments are printed, along with the original DataFrame if desired.","metadata":{}},{"cell_type":"code","source":"import pandas as pd\n\n# Initialize an empty list to store predictions\npredictions = []\n\nTEXT = \"I liked this movie because\"\nN_WORDS = 40\nN_SENTENCES = 2\n\n# Generate multiple sentences\nfor _ in range(N_SENTENCES):\n    # Generate a prediction for the given text\n    pred = learn.predict(TEXT)  # Assuming this returns (generated_text, sentiment)\n\n    # Extract generated text and sentiment from the prediction\n    generated_text = pred[0]  # Adjust index based on your output structure\n    sentiment = pred[1]        # Adjust index based on your output structure\n\n    # Store both the text and sentiment\n    predictions.append((generated_text, sentiment))\n\n    # Update TEXT with the last generated prediction for the next sentence generation\n    TEXT += ' ' + generated_text  # Continue the text\n\n# Create a DataFrame from the predictions\npredictions_df = pd.DataFrame(predictions, columns=['Generated Review', 'Sentiment'])\n\n# Print the generated sentences with their sentiments\nfor i, (sentence, sentiment) in enumerate(predictions):\n    print(f\"Review {i + 1}: {sentence} (Sentiment: {sentiment})\")\n\n# Print the entire DataFrame\nprint(\"\\nAll Generated Reviews:\")\nprint(predictions_df)\n\n# If you want to print the original DataFrame as well\n# Assuming `train_df` is your original DataFrame\nprint(\"\\nOriginal DataFrame:\")\nprint(train_df)\n","metadata":{"execution":{"iopub.status.busy":"2024-10-31T11:12:18.092527Z","iopub.execute_input":"2024-10-31T11:12:18.093073Z","iopub.status.idle":"2024-10-31T11:12:18.176721Z","shell.execute_reply.started":"2024-10-31T11:12:18.093028Z","shell.execute_reply":"2024-10-31T11:12:18.175711Z"},"trusted":true},"execution_count":88,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/fastai/callback/fp16.py:47: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  self.autocast,self.learn.scaler,self.scales = autocast(dtype=dtype),GradScaler(**self.kwargs),L()\n/opt/conda/lib/python3.10/site-packages/fastai/callback/fp16.py:47: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n  self.autocast,self.learn.scaler,self.scales = autocast(dtype=dtype),GradScaler(**self.kwargs),L()\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n<style>\n    /* Turns off some styling */\n    progress {\n        /* gets rid of default border in Firefox and Opera. */\n        border: none;\n        /* Needs to be in here for Safari polyfill so background images work as expected. */\n        background-size: auto;\n    }\n    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n    }\n    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n        background: #F44336;\n    }\n</style>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/fastai/callback/fp16.py:47: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  self.autocast,self.learn.scaler,self.scales = autocast(dtype=dtype),GradScaler(**self.kwargs),L()\n/opt/conda/lib/python3.10/site-packages/fastai/callback/fp16.py:47: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n  self.autocast,self.learn.scaler,self.scales = autocast(dtype=dtype),GradScaler(**self.kwargs),L()\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n<style>\n    /* Turns off some styling */\n    progress {\n        /* gets rid of default border in Firefox and Opera. */\n        border: none;\n        /* Needs to be in here for Safari polyfill so background images work as expected. */\n        background-size: auto;\n    }\n    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n    }\n    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n        background: #F44336;\n    }\n</style>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"name":"stdout","text":"Review 1: positive (Sentiment: 2)\nReview 2: positive (Sentiment: 2)\n\nAll Generated Reviews:\n  Generated Review  Sentiment\n0         positive  tensor(2)\n1         positive  tensor(2)\n\nOriginal DataFrame:\n     Unnamed: 0  rating  \\\n29           29       5   \n535         535       4   \n695         695       1   \n557         557       1   \n836         836       2   \n..          ...     ...   \n106         106       1   \n270         270       4   \n860         860       3   \n435         435       5   \n102         102       2   \n\n                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  reviewText  \\\n29                                                                                                   I have read tons of books, and this is one of the best books I've ever read! Imagine the concept of a hitch-hiking serial killer being picked up by a serial killer! It's hilarious! I've read all the versions and prequels and sequels that Kilborn and Crouch wrote about these characters, and let me tell you they are all great! They have some really twisted minds, and I love that. Kinda reminds me of myself lol. Keep it up you two, because I want to read more of your stuff! And don't ever hitchhike!!!   \n535                                                                                                                                                                                                                                                                                                                                                                                                                                       A great read. Nate and Emery's story was sweet. I really enjoyed the book from start to finish.  The electricity involved between them was epic. We need a few more men like Nate.   \n695                                                                                                                                                                                                                                                                                                                                                                                                                                               Ok I bought this because it was free and thought a cute short story - half way through it does this weird twist and I started laughing.  Not streamy but stupid - skip it.   \n557                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   Poorly written.  Good story.  Needs editor.  Rambles.  I would avoid the work--but give the author another chance should he try again.   \n836                                                                                                                                                                                                                                                                                                                                                                                      This book is not one of my faviourties, but that may be because I was not expecting the unexpected, I did read the whole book and enjoyed the story line and some of the quirky lines, and the story flowed.sorry it is me not you.   \n..                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       ...   \n106                                                                                                                                                                                                                                                                          I got this book and the second one(The werewolf whisper) as a pair...if I had not, I would not have read the second one.  The story is choppy and the second book made me laugh as it was not built up to be believible...but for $3.99 for the both, what did I really expect.  There is a third book, but I don't care how this story ends...   \n270  Aidan is a futuristic transport pilot on the hook for her brother's gambling debts. Warwick is masked muscle for a corrupt businessman as he saves up for the revenge of the death of his parents. When they meet up, sparks fly and worlds tremble.Icy Heat isn't going to win any \"best written book ever\" awards, but I really liked it. And I don't usually like or read futuristic sci/fi novels. Definitely character driven, this story is way more about the people, Aidan and Warwick, than it is about world building or plot development - and that's okay. I wasn't expecting it to be heavy in those ar...   \n860                                   Jules Verne has a knack for detail.  This book has a good plot and a mystery not solved until the end.  This keeps one reading even though it is a very tedious chore.  Similar with many writers the object is to keep wandering around many irrelevant ideas to add &#34;texture&#34;.  I suspect most readers read a line or two each page in order to make some headway into the story.  One also has to accept absurd achievements similar to a James Bond movie.  It's better to read this than some sex novel written by someone with a demented mind.  Lynn in Jacksonville OR   \n435                                                                                                                                                                                                                                                                                                                                          this was one of the most interesting books I have read. it keeps you in suspense throughout the entire book it is amazing how much these men accomplished while on the island I loved the book, and couldn't, put it down I would recommend this book to all adventure readers.   \n102                                                                                                                                                                                                                                                                                                                                                                                                                                                                          Storyline could have been better and it was slow. It took to long to get to the threesome. As long as it it VERY cheap it is somewhat worth it.   \n\n                               summary sentiment  \n29            The greatest story ever!  positive  \n535                             Great.  positive  \n695  Don't Buy - even though it's free  negative  \n557               Close --But No Cigar  negative  \n836                         Blind Date  negative  \n..                                 ...       ...  \n106                       O.K....kinda  negative  \n270            Fast and Fun Light Read  positive  \n860                  mysterious island   neutral  \n435              The mysterious island  positive  \n102             could have been better  negative  \n\n[800 rows x 5 columns]\n","output_type":"stream"}]},{"cell_type":"markdown","source":"This code creates a TextDataLoaders object for text classification using a DataFrame df, specifying reviewText as the text column and rating as the label column, with 20% of the data reserved for validation and a batch size of 16. It then checks the shapes of the input and target tensors for the first training batch to verify the setup.","metadata":{"execution":{"iopub.status.busy":"2024-10-31T10:55:58.317055Z","iopub.execute_input":"2024-10-31T10:55:58.317475Z","iopub.status.idle":"2024-10-31T10:55:58.326710Z","shell.execute_reply.started":"2024-10-31T10:55:58.317427Z","shell.execute_reply":"2024-10-31T10:55:58.324923Z"}}},{"cell_type":"code","source":"\ndls_clas = TextDataLoaders.from_df(\n    df,\n    text_col='reviewText',  # Make sure this column exists\n    label_col='rating',      # Adjust this to the actual label column (e.g., 'rating' or whatever you see)\n    valid_pct=0.2,           # 20% for validation\n    bs=16                    # Adjust batch size as needed\n)\n\n# Step 4: Check the DataLoader output\nfor x, y in dls_clas.train:\n    print(f\"Input shape: {x.shape}, Target shape: {y.shape}\")\n    break  # Check only the first batch","metadata":{"execution":{"iopub.status.busy":"2024-10-31T11:12:18.177873Z","iopub.execute_input":"2024-10-31T11:12:18.178153Z","iopub.status.idle":"2024-10-31T11:12:39.133425Z","shell.execute_reply.started":"2024-10-31T11:12:18.178122Z","shell.execute_reply":"2024-10-31T11:12:39.132263Z"},"trusted":true},"execution_count":89,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n<style>\n    /* Turns off some styling */\n    progress {\n        /* gets rid of default border in Firefox and Opera. */\n        border: none;\n        /* Needs to be in here for Safari polyfill so background images work as expected. */\n        background-size: auto;\n    }\n    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n    }\n    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n        background: #F44336;\n    }\n</style>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"name":"stdout","text":"Input shape: torch.Size([16, 2613]), Target shape: torch.Size([16])\n","output_type":"stream"}]},{"cell_type":"markdown","source":"This code initializes a text classification learner using Fastai, specifically with the AWD-LSTM architecture, by creating a Learner object (learn) with the following parameters:\n\ndls_clas: The DataLoaders object containing the training and validation data.\nAWD_LSTM: The model architecture being used for text classification.\ndrop_mult=0.5: A drop-out multiplier applied to the drop-out rates in the model, helping to prevent overfitting.\nmetrics=accuracy: Specifies that accuracy will be used as the evaluation metric during training and validation","metadata":{}},{"cell_type":"code","source":"learn = text_classifier_learner(dls_clas, AWD_LSTM, drop_mult=0.5, metrics=accuracy)","metadata":{"execution":{"iopub.status.busy":"2024-10-31T11:12:39.135175Z","iopub.execute_input":"2024-10-31T11:12:39.135559Z","iopub.status.idle":"2024-10-31T11:12:39.848696Z","shell.execute_reply.started":"2024-10-31T11:12:39.135522Z","shell.execute_reply":"2024-10-31T11:12:39.847676Z"},"trusted":true},"execution_count":90,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/fastai/text/learner.py:149: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  wgts = torch.load(wgts_fname, map_location = lambda storage,loc: storage)\n","output_type":"stream"}]},{"cell_type":"markdown","source":"This code trains the text classification model (learn) on the provided data for 10 epochs using the \"one cycle\" learning rate policy. The fit_one_cycle(10) method adjusts the learning rate dynamically during training to optimize performance and helps in improving convergence and generalization of the model.","metadata":{}},{"cell_type":"code","source":"# Train the model on your data\nlearn.fit_one_cycle(10)","metadata":{"execution":{"iopub.status.busy":"2024-10-31T11:12:39.850225Z","iopub.execute_input":"2024-10-31T11:12:39.850908Z","iopub.status.idle":"2024-10-31T11:21:41.855843Z","shell.execute_reply.started":"2024-10-31T11:12:39.850859Z","shell.execute_reply":"2024-10-31T11:21:41.854814Z"},"trusted":true},"execution_count":91,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n<style>\n    /* Turns off some styling */\n    progress {\n        /* gets rid of default border in Firefox and Opera. */\n        border: none;\n        /* Needs to be in here for Safari polyfill so background images work as expected. */\n        background-size: auto;\n    }\n    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n    }\n    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n        background: #F44336;\n    }\n</style>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: left;\">\n      <th>epoch</th>\n      <th>train_loss</th>\n      <th>valid_loss</th>\n      <th>accuracy</th>\n      <th>time</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>0</td>\n      <td>1.442760</td>\n      <td>1.358410</td>\n      <td>0.404167</td>\n      <td>00:54</td>\n    </tr>\n    <tr>\n      <td>1</td>\n      <td>1.367324</td>\n      <td>1.242512</td>\n      <td>0.455417</td>\n      <td>00:54</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>1.316873</td>\n      <td>1.239696</td>\n      <td>0.452500</td>\n      <td>00:53</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>1.295009</td>\n      <td>1.232053</td>\n      <td>0.456250</td>\n      <td>00:53</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>1.309603</td>\n      <td>1.224925</td>\n      <td>0.448750</td>\n      <td>00:53</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>1.260188</td>\n      <td>1.213343</td>\n      <td>0.466250</td>\n      <td>00:53</td>\n    </tr>\n    <tr>\n      <td>6</td>\n      <td>1.240828</td>\n      <td>1.204823</td>\n      <td>0.471250</td>\n      <td>00:53</td>\n    </tr>\n    <tr>\n      <td>7</td>\n      <td>1.237287</td>\n      <td>1.204736</td>\n      <td>0.471667</td>\n      <td>00:56</td>\n    </tr>\n    <tr>\n      <td>8</td>\n      <td>1.244697</td>\n      <td>1.204505</td>\n      <td>0.480000</td>\n      <td>00:54</td>\n    </tr>\n    <tr>\n      <td>9</td>\n      <td>1.223475</td>\n      <td>1.207533</td>\n      <td>0.476250</td>\n      <td>00:54</td>\n    </tr>\n  </tbody>\n</table>"},"metadata":{}}]},{"cell_type":"markdown","source":"This code creates a TextDataLoaders object with a vocabulary limit of 896 tokens, initializes a text classification learner using the AWD-LSTM model, retrains it for 1 epoch, and saves the encoder as 'finetuned_encoder'.","metadata":{}},{"cell_type":"code","source":"\n# Create DataLoaders with a limited vocabulary\ndls = TextDataLoaders.from_df(\n    df,\n    text_col='reviewText',\n    label_col='rating',\n    valid_pct=0.2,\n    bs=16,\n    max_vocab=896  # Limit to 896 unique tokens\n)\n\n# Create a learner\nlearn = text_classifier_learner(dls_clas, AWD_LSTM, drop_mult=0.5, metrics=accuracy)\n\n# You may need to retrain the model\nlearn.fit_one_cycle(1)\n\n# Save the encoder if desired\nlearn.save_encoder('finetuned_encoder')","metadata":{"execution":{"iopub.status.busy":"2024-10-31T11:21:41.857809Z","iopub.execute_input":"2024-10-31T11:21:41.858890Z","iopub.status.idle":"2024-10-31T11:22:59.520327Z","shell.execute_reply.started":"2024-10-31T11:21:41.858836Z","shell.execute_reply":"2024-10-31T11:22:59.519263Z"},"trusted":true},"execution_count":92,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n<style>\n    /* Turns off some styling */\n    progress {\n        /* gets rid of default border in Firefox and Opera. */\n        border: none;\n        /* Needs to be in here for Safari polyfill so background images work as expected. */\n        background-size: auto;\n    }\n    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n    }\n    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n        background: #F44336;\n    }\n</style>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/fastai/text/learner.py:149: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  wgts = torch.load(wgts_fname, map_location = lambda storage,loc: storage)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n<style>\n    /* Turns off some styling */\n    progress {\n        /* gets rid of default border in Firefox and Opera. */\n        border: none;\n        /* Needs to be in here for Safari polyfill so background images work as expected. */\n        background-size: auto;\n    }\n    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n    }\n    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n        background: #F44336;\n    }\n</style>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: left;\">\n      <th>epoch</th>\n      <th>train_loss</th>\n      <th>valid_loss</th>\n      <th>accuracy</th>\n      <th>time</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>0</td>\n      <td>1.348533</td>\n      <td>1.268514</td>\n      <td>0.432083</td>\n      <td>00:54</td>\n    </tr>\n  </tbody>\n</table>"},"metadata":{}}]},{"cell_type":"markdown","source":"This code trains the text classification model (learn) for 1 epoch using the \"one cycle\" learning rate policy, with a maximum learning rate set to \n2\n×\n1\n0\n−\n2\n2×10 \n−2\n  (0.02). This approach helps in optimizing the model's performance by dynamically adjusting the learning rate during training.","metadata":{}},{"cell_type":"code","source":"learn.fit_one_cycle(1, 2e-2)","metadata":{"execution":{"iopub.status.busy":"2024-10-31T11:22:59.521771Z","iopub.execute_input":"2024-10-31T11:22:59.522447Z","iopub.status.idle":"2024-10-31T11:23:53.599779Z","shell.execute_reply.started":"2024-10-31T11:22:59.522409Z","shell.execute_reply":"2024-10-31T11:23:53.598661Z"},"trusted":true},"execution_count":93,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n<style>\n    /* Turns off some styling */\n    progress {\n        /* gets rid of default border in Firefox and Opera. */\n        border: none;\n        /* Needs to be in here for Safari polyfill so background images work as expected. */\n        background-size: auto;\n    }\n    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n    }\n    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n        background: #F44336;\n    }\n</style>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: left;\">\n      <th>epoch</th>\n      <th>train_loss</th>\n      <th>valid_loss</th>\n      <th>accuracy</th>\n      <th>time</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>0</td>\n      <td>1.325174</td>\n      <td>1.251211</td>\n      <td>0.457083</td>\n      <td>00:54</td>\n    </tr>\n  </tbody>\n</table>"},"metadata":{}}]},{"cell_type":"markdown","source":"This code snippet performs the following actions:\n\nFreezes Layers: The method learn.freeze_to(-2) freezes all layers of the model except for the last two, allowing only those layers to be trained. This helps in fine-tuning the model by focusing on the most relevant parts of the architecture while keeping the rest stable.\n\nTrains the Model: The fit_one_cycle(1, slice(1e-2/(2.6**4), 1e-2)) method trains the model for 1 epoch using a one-cycle learning rate policy. The learning rate is set to vary between a lower bound of \n1\n𝑒\n−\n2\n(\n2.\n6\n4\n)\n(2.6 \n4\n )\n1e−2\n​\n  (approximately 0.0006) and an upper bound of \n1\n𝑒\n−\n2\n1e−2 (0.01). This dynamic adjustment helps optimize performance by allowing for both exploration and fine-tuning within the specified range.","metadata":{}},{"cell_type":"code","source":"learn.freeze_to(-2)\nlearn.fit_one_cycle(1, slice(1e-2/(2.6**4),1e-2))","metadata":{"execution":{"iopub.status.busy":"2024-10-31T11:23:53.601416Z","iopub.execute_input":"2024-10-31T11:23:53.601800Z","iopub.status.idle":"2024-10-31T11:24:54.874789Z","shell.execute_reply.started":"2024-10-31T11:23:53.601759Z","shell.execute_reply":"2024-10-31T11:24:54.873524Z"},"trusted":true},"execution_count":94,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n<style>\n    /* Turns off some styling */\n    progress {\n        /* gets rid of default border in Firefox and Opera. */\n        border: none;\n        /* Needs to be in here for Safari polyfill so background images work as expected. */\n        background-size: auto;\n    }\n    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n    }\n    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n        background: #F44336;\n    }\n</style>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: left;\">\n      <th>epoch</th>\n      <th>train_loss</th>\n      <th>valid_loss</th>\n      <th>accuracy</th>\n      <th>time</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>0</td>\n      <td>1.273855</td>\n      <td>1.145140</td>\n      <td>0.502917</td>\n      <td>01:01</td>\n    </tr>\n  </tbody>\n</table>"},"metadata":{}}]},{"cell_type":"code","source":"learn.freeze_to(-3)\nlearn.fit_one_cycle(1, slice(5e-3/(2.6**4),5e-3))","metadata":{"execution":{"iopub.status.busy":"2024-10-31T11:24:54.876309Z","iopub.execute_input":"2024-10-31T11:24:54.878521Z","iopub.status.idle":"2024-10-31T11:26:21.908492Z","shell.execute_reply.started":"2024-10-31T11:24:54.878481Z","shell.execute_reply":"2024-10-31T11:26:21.907376Z"},"trusted":true},"execution_count":95,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n<style>\n    /* Turns off some styling */\n    progress {\n        /* gets rid of default border in Firefox and Opera. */\n        border: none;\n        /* Needs to be in here for Safari polyfill so background images work as expected. */\n        background-size: auto;\n    }\n    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n    }\n    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n        background: #F44336;\n    }\n</style>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: left;\">\n      <th>epoch</th>\n      <th>train_loss</th>\n      <th>valid_loss</th>\n      <th>accuracy</th>\n      <th>time</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>0</td>\n      <td>1.149039</td>\n      <td>1.080518</td>\n      <td>0.516250</td>\n      <td>01:27</td>\n    </tr>\n  </tbody>\n</table>"},"metadata":{}}]},{"cell_type":"code","source":"learn.unfreeze()\nlearn.fit_one_cycle(2, slice(1e-3/(2.6**4),1e-3))","metadata":{"execution":{"iopub.status.busy":"2024-10-31T11:26:21.910203Z","iopub.execute_input":"2024-10-31T11:26:21.910639Z","iopub.status.idle":"2024-10-31T11:30:02.420561Z","shell.execute_reply.started":"2024-10-31T11:26:21.910589Z","shell.execute_reply":"2024-10-31T11:30:02.419546Z"},"trusted":true},"execution_count":96,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n<style>\n    /* Turns off some styling */\n    progress {\n        /* gets rid of default border in Firefox and Opera. */\n        border: none;\n        /* Needs to be in here for Safari polyfill so background images work as expected. */\n        background-size: auto;\n    }\n    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n    }\n    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n        background: #F44336;\n    }\n</style>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: left;\">\n      <th>epoch</th>\n      <th>train_loss</th>\n      <th>valid_loss</th>\n      <th>accuracy</th>\n      <th>time</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>0</td>\n      <td>1.062047</td>\n      <td>1.024469</td>\n      <td>0.538333</td>\n      <td>01:49</td>\n    </tr>\n    <tr>\n      <td>1</td>\n      <td>1.028064</td>\n      <td>1.018642</td>\n      <td>0.538750</td>\n      <td>01:50</td>\n    </tr>\n  </tbody>\n</table>"},"metadata":{}}]}]}